{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Algoritmos_MPI_SCP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/desarrollo/MPI/03_Algoritmos_MPI_SCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gde4FA2b-KeX"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>Algoritmos MPI</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M.en.C. Miguel Angel Pérez León</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Mario Arturo</i></h5>\n",
        "  <h5 align=\"center\"><i>Materia: Seminario de programación en paralelo</i></h5>\n",
        "  </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqJZuAbB-KeZ"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "Ya que hemos visto algunos métodos interesantes previamente (Monte Carlo) el siguiente paso consiste en convertir la versión secuencial de estos algoritmos a su versión en paralelo.\n",
        "\n",
        "Para ello vamos a comenzar con el ejemplo básico de la aproximación de $\\pi$ empleando métodos de Monte Carlo, tal como se mostró en la presentación previa, en la cual se describe el desarrollo y marco teórico de dicho método.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHFG33_0-Keb"
      },
      "source": [
        "# Aproximación de $\\pi$ mediante Monte Carlo\n",
        "\n",
        "Para la implementación de este algoritmo en paralelo utilizaremos *MPI* ya que tanto el método y el algoritmo son ideales para tal propósito.\n",
        "\n",
        "Vale la pena aclarar que la idea de los métodos de Monte Carlo se basan en la generación de números aleatorios y es por esto que *MPI* es muy buena idea para este tipo de algoritmos, ya que *MPI* originalmente se creo para arquitecturas sin memoria compartida (envío de mensajes).\n",
        "\n",
        "A continuación podemos ver el algoritmo para la aproximación de $\\pi$ haciendo uso de *MPI*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoVbQ3wTrpig"
      },
      "source": [
        "codigo = \"\"\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <mpi.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "void Validar_Entrada(int argc, int id);\n",
        "long Lanzamientos(long numLanzamientoProc, int miRango);\n",
        " \n",
        "int main(int argc, char* argv[]){\n",
        "   // Bloque de variables\n",
        "   int lan, id_procesador, num_procesadores, total_dardos_dentro, dardo_dentro_proc, lanzamiento_procesador;\n",
        "   double tiempo_local, tiempo_final, tiempo_inicial, transcurrido, N, pi_aprox;\n",
        "   MPI_Init(&argc, &argv);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &id_procesador);\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &num_procesadores);\n",
        "   // se valida la entrada del usuario\n",
        "   Validar_Entrada(argc, id_procesador);\n",
        "   // Se guarda el numero total de lanzamientos\n",
        "   sscanf(argv[1], \"%lf\", &N);\n",
        "   // Bloqueo para esperar que cada procesador realice esta parte\n",
        "   MPI_Barrier(MPI_COMM_WORLD);\n",
        "   // tiempo inicial\n",
        "   tiempo_inicial = MPI_Wtime();\n",
        "   // lanzamiento por procesador\n",
        "   lanzamiento_procesador = N/num_procesadores;\n",
        "   // cada procesador realiza esta seccion\n",
        "   dardo_dentro_proc = Lanzamientos(lanzamiento_procesador, id_procesador);\n",
        "   // tiempo final\n",
        "   tiempo_final = MPI_Wtime();\n",
        "   // tiempo que tomo en cada procesador\n",
        "   tiempo_local = tiempo_final-tiempo_inicial;\n",
        "   // suma de cada dardo dentro de la circunferencia\n",
        "   MPI_Allreduce(&dardo_dentro_proc, &total_dardos_dentro, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n",
        "   // nos quedamos con el maximo de los tiempos, ya que eso fue lo que tomo\n",
        "   MPI_Allreduce(&tiempo_local, &transcurrido, 1, MPI_DOUBLE, MPI_MAX, MPI_COMM_WORLD); \n",
        "   // el proceso maestro se encarga de imprimir el resultado\n",
        "   if (id_procesador == 0) { \n",
        "      pi_aprox = (total_dardos_dentro*4)/((double)N);\n",
        "      lan = (int)N;\n",
        "      printf(\"Numero de lanzamientos:      \t    %d\\\\n\", lan);\n",
        "      printf(\"Valor aproximado de pi:       %24.16f\\\\n\", pi_aprox);\n",
        "      printf(\"Maximo tiempo transcurrido del procesador en segundos:  %.16f\\\\n\", transcurrido*100);\n",
        "   }\n",
        "   // se liberan los recursos utilizados\n",
        "   MPI_Finalize();\n",
        "   return 0;\n",
        "}\n",
        "\n",
        "// Funciona que valida la entrada del usuario\n",
        "void Validar_Entrada(int argc, int id){\n",
        "   // Validacion de la entrada\n",
        "   if( argc !=2){\n",
        "      if (id==0){\n",
        "         fprintf(stderr,\"Incorrect NARGIN\\\\n\");\n",
        "         fflush(stderr);\n",
        "      }\n",
        "   MPI_Abort(MPI_COMM_WORLD,1);\n",
        "   }  \n",
        "}\n",
        "\n",
        "// Funcion que simula los lanzamientos de los dardos\n",
        "long Lanzamientos(long numLanzamientoProc, int id_proc){\n",
        "   long lanzamiento, numeroEnCirculo = 0;        \n",
        "   double x,y;\n",
        "   unsigned int semilla = (unsigned) time(NULL);\n",
        "   srand(semilla + id_proc);\n",
        "   for (lanzamiento = 0; lanzamiento < numLanzamientoProc; lanzamiento++) {\n",
        "\tx = rand_r(&semilla)/(double)RAND_MAX;\n",
        "\ty = rand_r(&semilla)/(double)RAND_MAX;\n",
        "\tif((x*x+y*y) <= 1.0 ) numeroEnCirculo++;\n",
        "    }\n",
        "    return numeroEnCirculo;  \n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# se crea el archivo con permisos para escribir mediante python\n",
        "archivo_texto = open(\"aprox_PI.c\", \"w\")\n",
        "# se escribe el programa en el archivo \n",
        "archivo_texto.write(codigo)\n",
        "# se cierra el buffer de escritura\n",
        "archivo_texto.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9VZmsm3sANU"
      },
      "source": [
        "!mpicc aprox_PI.c -o aprox_PI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16RmriMOsSIw",
        "outputId": "ee156c96-06dc-4cd7-91cb-8d182a89582a"
      },
      "source": [
        "!mpirun --allow-run-as-root -np 100 ./aprox_PI 100000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de lanzamientos:      \t    100000\n",
            "Valor aproximado de pi:             3.1920000000000002\n",
            "Maximo tiempo transcurrido del procesador en segundos:  0.0131242000009024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYA0Fal3Z3Jt"
      },
      "source": [
        "## Análisis a secciones importantes\n",
        "\n",
        "*MPI_Abort(MPI_COMM_WORLD,1)*: en caso de que el usuario no introdusca los valores correctos el programa finaliza y todos los procesos asociados al mismo.\n",
        "\n",
        "*MPI_Barrier(MPI_COMM_WORLD)*: esta directiva obliga a que todos los hilos asignados a este procesador terminen antes de poder avanzar.\n",
        "\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/MPI/barrier.png?raw=1\" width=\"700\">\n",
        "\n",
        "*MPI_Allreduce(&dardo_dentro_proc, &total_dardos_dentro, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD)*: funciona de manera simular al reduce de OpenMP en el cual se realiza la reduccion de multiples variables en una sola."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0zl8srO-Kef"
      },
      "source": [
        "# Suma de los primeros $n$ números naturales\n",
        "\n",
        "En esta sección vamos a analizar un algoritmo ampliamente conocido y hasta cierto punto sencillo, sin embargo la idea de este seminario es mostrar las cualidades de la programación en paralelo y la suma de los primeros $n$ números naturales es un ejemplo ideal para ejemplificar el concepto de pase de mensajes entre procesos.\n",
        "\n",
        "A primera vista esta labor puede parecer algo trivial.\n",
        "\n",
        "$$\\sum_{i=1}^{n}i=\\frac{n(n+1)}{2}$$\n",
        "\n",
        "Sin embargo la complejidad de esta sección radica en, ¿cómo dividir esta labor en diferentes secciones en paralelo para poder reducir el tiempo de ejecución. La idea sería compartir entre todos los procesos (broadcast) el vector de elementos y realizar la suma parcial en cada proceso respectivo.\n",
        "\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/MPI/broadcast.png?raw=1\" width=\"700\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJmwGXOEhztj"
      },
      "source": [
        "codigo = \"\"\"\n",
        "#include <stdio.h>\n",
        "#include <mpi.h>\n",
        "#define tam 10000\n",
        "\n",
        "int main (int argc, char** argv){\n",
        "   // bloque de variables globales\n",
        "   int id_procesador, num_procesadores, a[tam], i, primero, ultimo, tam_porcion;\n",
        "   double suma_total = 0, suma_parcial = 0;\n",
        "   MPI_Status status;\n",
        "   MPI_Init(&argc, &argv);\n",
        "   MPI_Comm_rank(MPI_COMM_WORLD, &id_procesador);\n",
        "   MPI_Comm_size(MPI_COMM_WORLD, &num_procesadores);\n",
        "   // el proceso root (maestro) llena el vector a sumar\n",
        "   if (id_procesador == 0) \n",
        "      for (i=0;i<tam;i++)\n",
        "         a[i] = i + 1;\n",
        "   // se transmite el vector a todos los procesos\n",
        "   MPI_Bcast(a,tam,MPI_INT,0,MPI_COMM_WORLD);\n",
        "   // determinamos la seccion a sumar dependiendo del proceso\n",
        "   tam_porcion = tam/num_procesadores;\n",
        "   // en caso de ser el ultimo procesador se asignan los limites\n",
        "   if (id_procesador == num_procesadores - 1) {\n",
        "      primero = (num_procesadores - 1)*tam_porcion;\n",
        "      ultimo = tam - 1;\n",
        "   } // en otro caso\n",
        "   else {\n",
        "      primero = id_procesador*tam_porcion;\n",
        "      ultimo = (id_procesador + 1)*tam_porcion - 1;\n",
        "   }\n",
        "   // se realiza la suma parcial\n",
        "   for (i=primero; i<=ultimo; i++) \n",
        "      suma_parcial = suma_parcial + a[i];\n",
        "   // se juntan todas las sumas parciales\n",
        "   MPI_Reduce(&suma_parcial, &suma_total, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);\n",
        "   if (id_procesador == 0) \n",
        "      printf(\"La suma es: %10.0f\\\\n\", suma_total);\n",
        "   // se liberan los recursos utilizados\n",
        "   MPI_Finalize();\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "# se crea el archivo con permisos para escribir mediante python\n",
        "archivo_texto = open(\"sum_n.c\", \"w\")\n",
        "# se escribe el programa en el archivo \n",
        "archivo_texto.write(codigo)\n",
        "# se cierra el buffer de escritura\n",
        "archivo_texto.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLKd0YH__eRn"
      },
      "source": [
        "!mpicc sum_n.c -o sum_n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwDpoceW_nOT",
        "outputId": "6efd9bc3-6707-4c08-ed01-502c509be328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!mpirun --allow-run-as-root -np 100 ./sum_n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La suma es:   50005000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJG5lGDp_2HN"
      },
      "source": [
        "## Nuevas funciones (broadcast)\n",
        "\n",
        "Una de las nuevas funciones es la función *MPI_Bcast(a,tam,MPI_INT,0,MPI_COMM_WORLD);*, está se encarga de difundir (broadcast) el mensaje que incluyen los datos a procesar.\n",
        "\n",
        "Una vez que cada proceso tiene la información pertinente, solo es cuestión de procesarla (realizar la suma parcial) y finalmente devolver el resultado mediante *reduce*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi2famUv-Kex"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "*   [Teorema Fundamental de Monte Carlo](https://www.ugr.es/~jillana/Docencia/FM/mc.pdf).\n",
        "*   [Ejemplos MPI (mallas)](https://htor.inf.ethz.ch/teaching/mpi_tutorials/ppopp13/2013-02-24-ppopp-mpi-basic.pdf)\n",
        "*   [Ejemplos MPI (juego de la vida)](https://cimec.org.ar/~mstorti/curso-mpi-petsc/slides.pdf)"
      ]
    }
  ]
}