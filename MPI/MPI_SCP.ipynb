{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MPI_SCP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/desarrollo/MPI/MPI_SCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaqO9ukN90TX"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>MPI (Intercambio de Mensajes)</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M.en.C. Miguel Angel Pérez León</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Mario Arturo Nieto Butron</i></h5>\n",
        "  <h5 align=\"center\"><i>Materia: Seminario de programación en paralelo</i></h5>\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSSSzHnlC26v"
      },
      "source": [
        "#Introducción\n",
        "\n",
        "Hoy en día existe una gran cantidad de lenguajes para realizar computo en paralelo. Muchos de ellos, lenguajes de alto nivel que facilitan (y ocultan) muchos de los aspectos de manejar computo en paralelo.\n",
        "\n",
        "Sin embargo hasta el momento no existe un solo lenguaje de alto nivel (por ejemplo java o python) que haya sido aceptado ampliamente por la comunidad del computo en paralelo.\n",
        "\n",
        "La mayor parte del computo en paralelo se realiza utilizando lenguajes como *Fortran o C*, con funciones aumentadas (Message Passing Intreface MPI) que realizan el pase de mensajes entre procesos.\n",
        "\n",
        "MPI continua siendo el estándar mas popular para el modelo de programación en paralelo mediante pase de mensajes.\n",
        "\n",
        "Podríamos decir que la mayoría de las p.c's. actuales dan soporte para MPI y a su vez existen bibliotecas gratuitas que permiten realizar computo en paralelo.\n",
        "\n",
        "Al igual que OpenMP, MPI es un conjunto de bibliotecas, funciones y directivas de compilador (API) que permite programar en paralelo en conjunto con lenguajes como* Fortran, C o C++*.\n",
        "\n",
        "La principal característica de MPI es que este no se basa en un modelo de memoria compartida, por lo que la comunicación entre procesos se realiza mediante paso de mensajes.\n",
        "\n",
        "Originalmente este API surgió con la intención de ser usado en un cluster (mediante una red), sin embargo con las crecientes mejoras en las arquitecturas de computadoras, MPI fue adaptado para sacar provecho de las mismas.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/MPI/modelo.png?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "En estas 2 imágenes se muestra el modelo empleado por MPI, en el cuál no se tiene una memoria compartida (como con OpenMP) y los procesos se comunican mediante la red (network). Sin embargo en las arquitecturas actuales, en las cuales se tienen múltiples CPU's en una (o mas placas madre), la comunicación entre los mismos se realiza mediante el **BUS del sistema** que substituye a la red.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/MPI/distributed_mem.gif?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "A diferencia de como funciona OpenMP, en MPI se tienen múltiples hilos (procesos ligeros) desde que comienza y hasta que termina el programa y la comunicación entre los distintos procesos se realiza mediante pase de mensajes.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/MPI/initfinal.png?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYctvrA4909M"
      },
      "source": [
        "# Desempeño\n",
        "\n",
        "Como ya se menciono MPI surge de la necesidad de realizar programación en paralelo sin asumir que se cuenta con una arquitectura en la cuál se tiene memoria compartida.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfY5noetEVOA"
      },
      "source": [
        "## ¿Como funciona?\n",
        "\n",
        "La forma tradicional de la programación en paralelo empleando paso de mensajes es la siguiente:\n",
        "\n",
        "*   Desde el momento en que se ejecuta un programa, se genera el número de procesos que llevaran a cabo el algoritmo.\n",
        "*   Los procesos se comunican entre si enviando mensajes con la información necesaria.\n",
        "*   Al termino de la o las secciones en paralelo, se junta el resultado del computo que hayan llevado a cabo los procesos.\n",
        "*   Se devuelve un único resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzxML9tSElN7"
      },
      "source": [
        "## Ventajas\n",
        "\n",
        "La principal diferencia entre MPI y OpenMPes que en este ultimo, se comienza y se termina con un solo hilo y en MPI desde que comienza el algoritmo se tienen varios procesos activos.\n",
        "\n",
        "Su principal ventaja es que **no se requiere arquitectura de memoria compartida** por lo que MPI puede ser empleando en casi cualquier sistema de computo en paralelo.\n",
        "\n",
        "Los elementos que intervienen cuando se emplea MPI son: el **proceso que envía, el que recibe y el mensaje**.\n",
        "\n",
        "Dependiendo de si el proceso que envía el mensaje requiere esperar o no, podemos pensar en que el paso de mensajes es de tipo **síncrono** o **asíncrono**.\n",
        "\n",
        "Dentro del paso de mensajes síncrono se engloba a las **llamadas a procedimiento remoto**, que son muy populares en las arquitecturas cliente/servidor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtPsRRfHE6e0"
      },
      "source": [
        "# MPI (API)\n",
        "\n",
        "Una vez que se tiene claro el funcionaiento de MPI, veamos los componentes principales de este API, que al igual que OpenMP se trata de un conjunto de bibliotecas, funciones y directivas de compilador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3tkBuVEFL1W"
      },
      "source": [
        "## Funciones importantes\n",
        "\n",
        "Con MPI básicamente lo que tendremos son funciones y algunas de ellas son:\n",
        "\n",
        "*   *MPI_Init*: instrucción que indica que haremos uso de MPI, si ella no es posible utilizar MPI.\n",
        "*   *MPI_Comm_rank*: devuelve el identificador de un proceso.\n",
        "*   *MPI_Comm_size*: muestra el numero de procesos.\n",
        "*   *MPI_Reduce*: operación de reducción como en OpenMP.\n",
        "*   *MPI_Finalize*: desconecta las funciones de MPI.\n",
        "*   *MPI_Barrier*: función para sincronizar los procesos existentes.\n",
        "*   *MPI_Wtime*: devuelve el tiempo en el momento de ser llamada.\n",
        "*   *MPI_Wtick*: determina la precisión del timer.\n",
        "\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9h06jfLF5gy"
      },
      "source": [
        "# Compilación y Ejecución\n",
        "\n",
        "Dado que MPI sigue siendo un API construido sobre el lenguaje *C/C++*, compilar y ejecutar un programa creado con MPI es similar a como se compila y ejecuta cualquier programa escrito en *C/C++*.\n",
        "\n",
        "En esta sección verwmos como compilar y ejecutar programas escritos mediante MPI tanto en google colab como en un equipo local."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLQCNknGXBxD"
      },
      "source": [
        "## MPI en Google Colab\n",
        "\n",
        "Normalmente una vez iniciada la sesión de *google colab*, esta ya cuenta con todo lo necesario para compilar y ejecutar un programa usando MPI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4V3utO8U3CZ"
      },
      "source": [
        "# variable de tipo String que en si es el programa\n",
        "codigo = \"\"\"\n",
        "#include <mpi.h> //biblioteca de MPI\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    // Llamada principal a las funciones de MPI\n",
        "    MPI_Init(NULL, NULL);\n",
        "\n",
        "    // Se obtiene el numero de procesos y se guarda en \n",
        "    int tam_mundo;\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &tam_mundo);\n",
        "\n",
        "    // Obtenemos el ID de cada proceso\n",
        "    int id_proceso;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &id_proceso);\n",
        "\n",
        "    // Obtenemos el nombre del procesador\n",
        "    char nombre_procesador[MPI_MAX_PROCESSOR_NAME];\n",
        "    int tam_nombre;\n",
        "    MPI_Get_processor_name(nombre_procesador, &tam_nombre);\n",
        "\n",
        "    // Se imprime el mensaje completo\n",
        "    printf(\"Hola mundo desde el procesador %s, id %d de un total de %d processors\\\\n\",\n",
        "           nombre_procesador, id_proceso, tam_mundo);\n",
        "\n",
        "    // Cerramos las herramientas de MPI.\n",
        "    MPI_Finalize();\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# se crea el archivo con permisos para escribir mediante python\n",
        "archivo_texto = open(\"hola.c\", \"w\")\n",
        "# se escribe el programa en el archivo \n",
        "archivo_texto.write(codigo)\n",
        "# se cierra el buffer de escritura\n",
        "archivo_texto.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaeuU1ndXQZ0"
      },
      "source": [
        "Una vez que ya se creó el archivo llamado *hola.c* lo siguiente es compilar el programa con el comando *mpicc*, de manera muy similar a como se hace con OpenMP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5V5c2eRVDSX"
      },
      "source": [
        "!mpicc hola.c -o hola"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJmY_a3vXkSM"
      },
      "source": [
        "En caso de no tener errores, podemos proceder a ejecutar el programa (binario hola) notando que la bandera *--allow-run-as-root* solo se debe usar en *google colab*.\n",
        "\n",
        "La bandera *-np numero*, indica el número de procesos que se usarán al momento de la ejecución del programa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3pMIYGPVV_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d78bb6b-cbb3-4d2b-f438-9195e6f02585"
      },
      "source": [
        "!mpirun --allow-run-as-root -np 4 hola"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hola mundo desde el procesador f9fc85deca0a, id 0 de un total de 4 processors\n",
            "Hola mundo desde el procesador f9fc85deca0a, id 1 de un total de 4 processors\n",
            "Hola mundo desde el procesador f9fc85deca0a, id 2 de un total de 4 processors\n",
            "Hola mundo desde el procesador f9fc85deca0a, id 3 de un total de 4 processors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgkYa9znF9Er"
      },
      "source": [
        "## MPI en equipo local\n",
        "\n",
        "De igual manera que OpenMP, una vez instalado el compilador y herramientas del lenguaje C (al menos en s.o. Linux) el API de MPI ya esta incluido con estas.\n",
        "\n",
        "De tal forma que compilar y ejecutar código que emplea directivas y funciones de MPI es tan sencillo como:\n",
        "\n",
        "Para compilar: \n",
        "\n",
        "*\\$mpicc codigoc.c -o (salida.o) hola*\n",
        "\n",
        "El comando anterior compila (y en caso de no haber errores) y genera un archivo ejecutable (binario) que puede ser ejecutado de la siguiente manera:\n",
        "\n",
        "*\\$mpirun hola*\n",
        "\n",
        "Para ejecutar, se puede usar la bandera -np para indicar el numero de procesos que se desean generar:\n",
        "\n",
        "*\\$mpirun hola -np numero procesos*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RouR47xeGEv1"
      },
      "source": [
        "#Glosario\n",
        "\n",
        "Proceso: En el contexto de MPI un proceso, es un conjunto de instrucciones que son ejecutadas por el CPU.\n",
        "\n",
        "Asíncrono: En computación un evento (proceso) asíncrono es aquel no tiene correspondencia temporal con otro evento. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6A4TOBfGOQt"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "1. Michaell J. Quuin: Parallel Programming in C with OpenMP and MPI.\n",
        "2. https://lsi.ugr.es/jmantas/ppr/ayuda/mpi_ayuda.php\n",
        "3. Dongarra Foster: Source Book of parallel computing."
      ]
    }
  ]
}