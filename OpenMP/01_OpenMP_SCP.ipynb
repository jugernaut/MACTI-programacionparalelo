{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenMP_SCP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/desarrollo/OpenMP/01_OpenMP_SCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBC0NKmEENHP"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>OpenMP (memoria compartida)</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M.en.C. Miguel Angel Pérez León</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Mario Arturo Nieto Butron</i></h5>\n",
        "  <h5 align=\"center\"><i>Materia: Seminario de programación en paralelo</i></h5>\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK0VO6YaG_Du"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "Aun en la década de los 80's adquirir una computadora con múltiples procesadores era costoso, incluso hoy en día el precio de una computadora depende en gran medida del número de procesadores que tenga.\n",
        "\n",
        "Actualmente comprar una computadora con varios *CPU's* y que a su vez estos *CPU's* contengan varios núcleos es relativamente accesible.\n",
        "\n",
        "Como ya se mencionó previamente, existen diferentes formas (paradigmas) de programación en paralelo, pero si la arquitectura lo permite (memoria compartida) se logra un buen desempeño haciendo uso *OpenMP*.\n",
        "\n",
        "*OpenMP* es un conjunto de bibliotecas, funciones y directivas de compilador (*API*) que permite programar en paralelo en conjunto con lenguajes como *Fortran*, *C/C++*.\n",
        "\n",
        "Es importante recordar que *OpenMP* se basa en la idea de dividir (*fork*) una tarea grande en tareas más pequeñas, para que finalmente los resultados sean unidos (*join*).\n",
        "\n",
        "A continuación se muestra el modelo de programación en paralelo mediante memoria compartida.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/openmp/mem.PNG?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "Diagrama del paradigma *fork-join*.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/OpenMP/thread3.png?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "En esta imágen, la linea azul muestra el avance del cómputo con respecto al tiempo.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/OpenMP/thread4.png?raw=1\" width=\"600\">\n",
        "</center> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJLgoXA8IVCl"
      },
      "source": [
        "# Desempeño\n",
        "\n",
        "La idea detrás de esta forma de procesamiento en paralelo, es dividir y vencer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBIFGoxeIcSL"
      },
      "source": [
        "## ¿Cómo funciona?\n",
        "\n",
        "La forma tradicional de la programación en paralelo empleando **memoria compartida** es la siguiente:\n",
        "\n",
        "• Cuando un programa comienza su ejecución un solo hilo llamado **hilo maestro** es activado.\n",
        "\n",
        "• El hilo maestro ejecuta la parte secuencial del algoritmo. En las secciones del algoritmo donde se requiera operaciones en paralelo, el hilo maestro genera (*fork*) **hilos adicionales** (esclavos).\n",
        "\n",
        "• El hilo maestro y los hilos adicionalmente creados, **trabajan de manera concurrente (o en paralelo)** a través de las secciones del algoritmo en paralelo.\n",
        "\n",
        "• Al termino de la o las secciones en paralelo, los hilos adicionales son **destruidos o suspendidos**.\n",
        "\n",
        "• Finalmente el control vuelve al hilo maestro y se **unen** (*join*) los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSlkKBEjIhCO"
      },
      "source": [
        "## Ventajas\n",
        "\n",
        "La principal diferencia entre *OpenMP* y *MPI* es que en este último, todos los procesos permanecen activos desde un inicio del programa, mientras que en *OpenMP* se comienza con un solo hilo y se termina con un solo hilo.\n",
        "\n",
        "Se puede pensar en la programación secuencial como un caso especial de la programación en paralelo usando memoria compartida (*OpenMP*).\n",
        "\n",
        "La programación en paralelo usando memoria compartida abarca algoritmos en los cuales se tiene un único ciclo *for* que se ejecuta con varios hilos, hasta aquellos algoritmos en los que la mayoria del código se ejecuta en paralelo.\n",
        "\n",
        "Por lo tanto este modelo de programación en paralelo soporta **paralelización incremental**, lo que significa que, un algoritmo secuencial puede ser transformado en uno algoritmo en paralelo un bloque a la vez.\n",
        "\n",
        "En contraste, al emplear *MPI* es necesario replantear el diseño del algoritmo, de manera tal que desde un principio funcione en paralelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tur77JgcEN-l"
      },
      "source": [
        "# OpenMP (API)\n",
        "\n",
        "Una vez que se tiene claro el funcionaiento de *OpenMP*, veamos los componentes principales de este *API* (interfaz de programación de aplicación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8ZwywSzI9HX"
      },
      "source": [
        "## Directivas de compilador\n",
        "\n",
        "Una directiva de compilador en *C/C++* es llamada **pragma**.\n",
        "\n",
        "La palabra *pragma*, es la contracción de ''información pragmática''.\n",
        "\n",
        "*Pragma* es una forma de comunicarle información al compilador, esta información no es esencial en el sentido del que el compilador puede ignorar dicha información y aun así compilar el código.\n",
        "\n",
        "Sin embargo la información dentro del *pragma* puede ayudar al compilador a optimizar el algoritmo.\n",
        "\n",
        "Al igual que otras lineas que proveen información al compilador, un pragma comienza con #."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj0UyAECJOxD"
      },
      "source": [
        "## Otras directivas de compilador\n",
        "\n",
        "Algunas de las directivas de compilador más importantes que veremos en esta sección son:\n",
        "\n",
        "1. **parallel**: que se usa antes de un bloque que sera ejecutado en paralelo por varios hilos.\n",
        "\n",
        "2. **for**: se usa antes de un ciclo for para indicar que las iteraciones de este ciclo serán ejecutadas en paralelo.\n",
        "\n",
        "3. **parallel for**: es una combinación de las 2 directivas previas.\n",
        "\n",
        "4. **sections**: indica que un conjunto de bloques será ejecutado en paralelo.\n",
        "\n",
        "5. **parallel sections**: combinación de *prallel* y *sections*.\n",
        "\n",
        "6. **critical**: se usa para indicar que una sección sera critica, por ejemplo para indicar que una sección de código solo puede ser accesible por un hilo a la vez.\n",
        "\n",
        "7. **single**: se usa antes de un bloque que sera ejecutado por un solo hilo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z79IN3G1Jxi8"
      },
      "source": [
        "## Funciones importantes\n",
        "\n",
        "Algunas funciones importantes que veremos en esta sección son:\n",
        "\n",
        "1. **omp_get_num_procs**: devuelve el numero de *CPU's* que tenga el núcleo en el cual se esta ejecutando el hilo.\n",
        "\n",
        "2. **omp_get_num_threads**: devuelve el número de hilos activos en la actual región en paralelo.\n",
        "\n",
        "3. **omp_get_thread_num**: devuelve el identificador del hilo.\n",
        "\n",
        "4. **omp_set_num_threads**: permite establecer el número de hilos que ejecutaran el código de la sección en paralelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_FFvlQOKD1q"
      },
      "source": [
        "# Compilación y Ejecución\n",
        "\n",
        "Una de las ventajas de *OpenMP* es que no requiere de instalación adicional a la que se realiza cuando se instala el compilador de *C/C++* (al menos en entornos *Linux*), solo es necesario usar las banderas (*flags*) correctas al momento de compilar.\n",
        "\n",
        "La manera en la que se compila (revisión sintáctica) y se ejecuta un programa codificado mediante *OpenMP*, es muy similar a como se compila y se ejecuta cualquier programa escrito en *C/C++*.\n",
        "\n",
        "Veamos como se compila y ejecuta tanto en *google colab*, como en un equipo local."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U4J7FrocIa1"
      },
      "source": [
        "## OpenMP en Google Colab\n",
        "\n",
        "Normalmente una vez iniciada la sesión de *google colab*, esta ya cuenta con todo lo necesario para compilar y ejecutar un programa usando *OpenMP*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSM96uxBcrYk"
      },
      "source": [
        "# variable de tipo String que en si es el programa\n",
        "codigo = \"\"\"\n",
        "// Hola Mundo con OpenMP \n",
        "// Encabezados de OpenMP y STD \n",
        "#include <omp.h>   \n",
        "#include <stdio.h> \n",
        "#include <stdlib.h> \n",
        "  \n",
        "int main(int argc, char* argv[]){ \n",
        "  \n",
        "    // Region en paralelo, que se ejecuta mediante hilos \n",
        "    #pragma omp parallel\n",
        "    { \n",
        "        printf(\"Hola Mundo... desde el hilo = %d \\\\n\", omp_get_thread_num()); \n",
        "    } \n",
        "    // Fin de la region en paralelo \n",
        "}\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnw75QXDdtYU"
      },
      "source": [
        "En la siguiente celda de código, se crea un archivo llamado *hola.c* y en el mismo se guarda el programa de la celda superior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cpxwVQcd3yP"
      },
      "source": [
        "# se crea el archivo con permisos para escribir mediante python\n",
        "archivo_texto = open(\"hola.c\", \"w\")\n",
        "# se escribe el programa en el archivo \n",
        "archivo_texto.write(codigo)\n",
        "# se cierra el buffer de escritura\n",
        "archivo_texto.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT0jdOr3eqCX"
      },
      "source": [
        "Generamos una variable de entorno, que defina el número de hilos que se van a utilizar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INuCne7Qe4EM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999f255e-fe7a-42e4-e457-5eb7ceaa1d8a"
      },
      "source": [
        "%env OMP_NUM_THREADS=3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: OMP_NUM_THREADS=3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g50UD41Pe8Wi"
      },
      "source": [
        "Para compilar se ejecuta el siguiente comando de *Linux*, el orden no importa y esta es la semantica de este comando:\n",
        "\n",
        "*   *!gcc*: llamada al compilador de *C/C++*, el \"!\" indica que es un comando de *Linux*.\n",
        "*   *-o hola*: *-o *es la bandera que indica cual será el nombre de salida (output), en este caso el binario de salida será llamado *hola*.\n",
        "*   *-fopenmp hola.c*: esta bandera indica que se hace uso del *API OpenMP* y que el archivo a compilar se llama *hola.c*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryRWgvwffC5V"
      },
      "source": [
        "!gcc -o hola -fopenmp hola.c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwVQCs5FgL7K"
      },
      "source": [
        "Dado que no se tiene algún mensaje de error, se asume que el programa se compilo de manera correcta. Incluso es posible revisar en el navegador de archivos o mediante comando de *Linux* que el binario *hola*, se generó de manera correcta.\n",
        "\n",
        "Finalmente solo resta ejecutar dicho archivo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX7PQ3YZgqlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e40c6a-988b-4a84-e944-f8afc38a37ed"
      },
      "source": [
        "!./hola"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hola Mundo... desde el hilo = 1 \n",
            "Hola Mundo... desde el hilo = 0 \n",
            "Hola Mundo... desde el hilo = 2 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_0pKijIKJSQ"
      },
      "source": [
        "## OpenMP en equipo local\n",
        "\n",
        "La manera de compilar y ejecutar en un equipo local es muy similar a los pasos previamente vistos.\n",
        "\n",
        "Lo primero es crear el programa y guardarlo en un archivo de texto plano, por ejemplo *codigo.c*.\n",
        "\n",
        "De tal forma que compilar y ejecutar código que emplea directivas y funciones de *OpenMP* es tan sencillo como:\n",
        "\n",
        "*   Para compilar: *\\$gcc -o salida -fopenmp codigo.c*\n",
        "\n",
        "El comando anterior compila (y en caso de no haber errores) y genera un archivo ejecutable (binario) que puede ser ejecutado de la siguiente manera:\n",
        " \n",
        "*   Para ejecutar:  *\\$./salida*\n",
        "\n",
        "Intenta compilar y ejecutar el programa *hola.c* en tu equipo local."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xg6mcCXKq5o"
      },
      "source": [
        "# Glosario\n",
        "\n",
        "**Hilo** (Thread): También conocido como proceso ligero, es el encargado de ejecutar tareas sencillas dentro de algún algoritmo. Varios hilos pueden conformar un proceso.\n",
        "\n",
        "**Núcleo** (core): En computación, un núcleo es una parte del microprocesador que se encarga de leer y ejecutar tareas. Actualmente se puede adquirir computadoras que cuenten con varios CPU's y que a su vez, estos contengan varios núcleos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoDz-nxRKuQ_"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "1. Michaell J. Quuin: Parallel Programming in C with OpenMP and MPI.\n",
        "2. https://hpc-wiki.info/hpc/OpenMP\n",
        "3. Dongarra Foster: Source Book of parallel computing."
      ]
    }
  ]
}