{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computo_en_paralelo_SCP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Introduccion/05_Computo_en_paralelo_SCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw2tNz_RtpGP"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>Cómputo en Paralelo</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M.en.C. Miguel Angel Pérez León.</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón.</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Mario Arturo Nieto Butron.</i></h5>\n",
        "  <h5 align=\"center\"><i>Materia: Seminario de programación en paralelo.</i></h5>\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Yf4M8Gu5Nl"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "El hardware se mejora constantemente y el día de mañana sera mas rápido que el día de hoy, así que como consecuencia de la **ley de Moore**, podríamos esperar a comprar una computadora mas \"rápida\" y eficiente que la que tenemos actualmente. Sin embargo mediante programación en paralelo, se pueden optimizar y agilizar los algoritmos empleados actualmente.\n",
        "\n",
        "**Ley de Moore:**\n",
        "\n",
        "El numero de **transistores** por unidad de superficie en circuitos integrados, se duplicara cada año. En consecuencia, la velocidad de computo relacionada directamente al hardware se vera duplicada cada año.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/ComputoParalelo/moore.png?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/ComputoParalelo/more2.jpg?raw=1\" width=\"900\"> \n",
        "</center>\n",
        "\n",
        "Antes de continuar con más conceptos podemos aterrizar lo antes mencionado para poder identificar que tan ponente es un dispositivo de cómputo. Normalmente los algoritmos computacionales involucran diferentes tipos de operaciones lógicas o aritméticas, sin embargo es común medir las capacidades de un dispositivo de cómputo en términos de las **operaciones de punto flotante que puede realizar por segundo** (FLOPS).\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/Introduccion/nomen.png?raw=1\" width=\"600\">\n",
        "</center> \n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/Introduccion/brontobyte.jpg?raw=1\" width=\"900\">\n",
        "</center>\n",
        "\n",
        "Ahora que ya se tiene una idea de como medir las capacidades de cómputo de algún dispositivo, veamos la [lista](https://www.top500.org/lists/top500/2020/11/) de las computadoras más potentes a nivel mundial.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/Introduccion/top500.png?raw=1\" width=\"900\">\n",
        "</center>\n",
        "\n",
        "De igual manera que los FLOPS son para los CPU's, tenemos los **GFLOPS** (operaciones de punto flontante por segundo dentro de un GPU) para los GPU's.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/Introduccion/GFLOPS.png?raw=1\" width=\"900\">\n",
        "</center>\n",
        "\n",
        "Digamos que estos son los datos \"a la vista\" (como cuando se juega poker), sin embargo existen supercomutadoras de las cuales no se tienen datos ya que son dispositivos utilizados por organismos militares y por lo tanto sus características son clasificadas. Recordemos esta historia curiosa sobre el cómputo y la segunda guerra mundial, en la cual haciendo uso de **criptografía** y dispositivos de cómputo, **Alan Turing** logro hackear el código enigma y así se logro descifrar los mensajes enviados por los alemanes, algunas estimaciones dicen que este logro recorto la campaña militar de la segunda guerra mundial en 2 años.\n",
        "\n",
        "Hasta comienzos de los 90's todo se hacia de manera secuencial, incluso sistemas como DOS es un sistema monotarea. Mas o menos hasta el año 2004 los desarrolladores de CPU's como IBM, Intel o AMD mejoraban sus dispositivos incrementando la **velocidad del reloj** (es un pulso en el cual se actualizan los registros) y se paso de 16 MHZ hasta 466 MHZ o incluso mas.\n",
        "\n",
        "Pero ya en 2004 era evidente que debido a las limitantes tecnológicas para incrementar las capacidades de computo se necesitaba buscar nuevas estrategias y una de estas nuevas estrategias fue introducir la innovación de agregar **más núcleos dentro de una CPU**. Por ejemplo un CPU con dos núcleos trabajando a 200 MHZ pueden ejecutar mas procesos que CPU con un solo núcleo a 300 MHZ.\n",
        "\n",
        "Para el año 2015 intel mostró su 8-core procesador, y posteriormente salieron al mercado procesadores de 10 núcleos, incluso en el mercado de equipos móviles se comenzó a ver un incremento en el numero de núcleos dentro de cada CPU, así que los programadores no pudieron ignorar la necesidad de comprender el funcionamiento de la **programación en paralelo**.\n",
        "\n",
        "Adicionalmente a lo antes mencionado, los desarrolladores de hardware rápidamente se dieron cuenta que no era muy complicado realizar ciertas modificaciones en cada núcleo para que este ejecutara 2 'tareas' y de esta manera optimizar y compartir recursos como la memoria cache. Así que esto nos lleva a definir un concepto muy importante que aparecen tanto en un CPU como en un GPU, **¿que es un hilo?**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kFLms3GKRXs"
      },
      "source": [
        "## Procesamiento de Cocos\n",
        "\n",
        "Este ejemplo fue tomado de la referencia (2) página 3, en este ejemplo vamos a hacer una analogía entre un conjunto de labores y el desarrollo de la programación en paralelo.\n",
        "\n",
        "Dos hermanos, Fredy y Jimmy tienen una granja de cocos, para cosechar sus cocos cuentan con 2 tractores y 2 martillos para romper los cocos. **El proceso de cosecha requiere de 2 tareas consecutivas** (cada una de ellas con una duración de 30 segundos):\n",
        "\n",
        "*   Tarea 1: ir del tractor a la palmera de cocos y traer uno a la vez.\n",
        "*   Tarea 2: romper (procesar) el coco usando el martillo y ponerlo en el tractor.\n",
        "\n",
        "Si cosechar por completo un coco requiere completar 2 tareas consecutivas (que de aquí en adelante **llamaremos hilos**) entonces ellos pueden cosechar 2 cocos por minuto dado que **pueden compartir el camino** y **cada uno tiene su propio martillo y tractor**. \n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/Introduccion/cocos.png?raw=1\" width=\"900\">\n",
        "</center> \n",
        "\n",
        "¿Podemos relacionar los elementos de esta analogía con los componentes del cómputo en paralelo?."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFQfVwxjRnMp"
      },
      "source": [
        "### Elementos\n",
        "\n",
        "En esta analogía: \n",
        "\n",
        "*   Cada tractor es un **núcleo**.\n",
        "*   Cosechar un coco es un **programa en ejecución**.\n",
        "*   Los cocos son **datos.**\n",
        "*   Fredy y Jimmy son **hilos en ejecución**.\n",
        "*   El martillo es la **unidad de ejecución tal como la ALU** dentro de cada núcleo.\n",
        "\n",
        "Este **programa** (cosecha de cocos) consiste de 2 hilos dependientes (no se puede ejecutar el hilo 2 sin haber ejecutado el hilo 1). La cantidad de cocos procesados (datos) es el **desempeño del programa**, a un mejor desempeño una mejor paga tendrán Fredy y Jimmy. El árbol de cocos es la **memoria de donde se toman datos**, así que la labor de obtener cocos en el hilo 1 es equivalente a leer datos de la memoria. De igual manera podemos pensar que **el camino que comparten Fredy y Jimmy es el BUS** del sistema de cómputo.\n",
        "\n",
        "Un día el tractor de Fredy se descompone y lo lleva al taller dejando el martillo dentro del tractor. Aun así ambos tienen que trabajar, con un solo tractor y un solo martillo, **¿aún pueden procesar 2 cocos por minuto?**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8U4T4gtXuWn"
      },
      "source": [
        "## Se descompone un tractor\n",
        "\n",
        "Ahora veamos que sucede si el tractor de Fredy se descompone, anteriormente ambos (Fredy y Jimmy) podían cosechar 2 cocos por minuto, pero ahora, **solo cuentan con un solo tractor y un solo martillo**. \n",
        "\n",
        "Conducen hasta la palmera de cocos y para cosechar cada coco necesitan **ejecutar la tarea 1 (hilo 1) y la tarea 2 (hilo 2) de manera consecutiva**. \n",
        "\n",
        "Ambos caminan hasta la palmera y traen el coco en 30 segundos (hilo 1), ahora tienen que romperlo pero **no lo pueden realizar de manera simultanea debido a que solo cuentan con 1 martillo.**\n",
        "\n",
        "Fredy tiene que esperar a que Jimmy rompa su coco (hilo 2 = 30 segundos) y deje de usar el martillo para que el lo pueda usar. Así que esto toma 30 segundos (el tiempo que Jimmy usa para romper su coco) + 30 segundos que le toma a Fredy romper su coco, de tal manera que total cosechar 2 cocos les tomo 90 segundos, así que **su desempeño cambio de 2 cocos por minuto a 2 cocos por 1.5 minutos**.\n",
        "\n",
        "Jimmy se pregunta, ¿existe forma de que volvamos a tener un desempeño de 2 cosos por minuto?."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMylZzRnYeI4"
      },
      "source": [
        "### Alternativas\n",
        "\n",
        "¿Por que Jimmy tiene que esperar a que Fredy desocupe el martillo, qué sucede si mientras Fredy usa el martillo (hilo 2) Jimmy se dedica a traer otro coco (hilo 1)?.\n",
        "\n",
        "Debido a que **ambas labores toman la misma cantidad de tiempo**, entonces ambos nunca estarán en la situación en la cuál se encuentren esperando que uno libere los recursos para poder hacer uso de los mismos.\n",
        "\n",
        "De tal manera que **ambos siempre se encontraran ocupados** y no se desperdician recursos. Esta genial ideal logra que su **desempeño vuelva a ser la de 2 cocos por minuto** sin la necesidad de un tractor y martillo adicional.\n",
        "\n",
        "Adicionalmente a esto, ¿qué sucede si Jimmy se dedica especificamente a traer los cocos (hilo 1) y Fredy a romperolos (hilo 2)?. **¿Cómo le llamaríamos a esta estratégia?**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRKoM2CUZ1dA"
      },
      "source": [
        "## Mejoras\n",
        "\n",
        "Estos 2 escenarios corresponden a la situación en la que se cuentan con **2 núcleos y cada núcleo ejecuta un hilo** (2C/1T) contra la situación en la que se cuenta con **un solo núcleo y este puede ejecutar 2 hilos** (1C/2T).\n",
        "\n",
        "En otras palabras **existen al menos 2 formas de darle la capacidad a un programa de ejecutar 2 hilos de manera simultanea** 2C/2T (Fredy y Jimy cada uno con su tractor y su martillo) ó 1C/2T (solo un tractor y martillo para Fredy y Jimmy).\n",
        "\n",
        "Analicemos algúnas otras mejoras, orgullosos del descubrimiento que llevo su desempeño de nuevo a 2 cocos por minuto, Jimmy quiere seguir investigando estrategias para optimizar los recursos disponibles para incrementar la eficiencia de su trabajo. Un día le dice a Fredy \"acabo de comprar un **martillo automatizado** que procesa un coco en 10 segundos\".\n",
        "\n",
        "Dado que ahora el hilo 1 toma (tomar por un coco) toma 30 segundos y el hilo 2 (romper el coco) toma 10 segundos, lo único que resta es organizar las tareas (diseño del programa), de tal manera que el hilo 2 no sea ejecutado de manera simultanea ya que solo se cuenta con un martillo automatizado (recursos compartidos).\n",
        "\n",
        "En otras palabras, el programa consiste en 2 hilos dependientes, el hilo 1 toma 30 segundos y no requiere recursos compartidos (memoria), el hilo 2 toma 10 segundos y no puede ser ejecutado de manera simultanea, ya que requiere de recursos compartidos (el martillo automatizado).\n",
        "\n",
        "Dado que cada coco requiere 30+10=40 segundos de tiempo total de ejecución, el mejor desempeño esperado es **2 cocos cada 40 segundos**.\n",
        "\n",
        "Finalmente, **pensemos que sucede si el camino (BUS del sistema), se restringe** a que solo una persona pueda usarlo.\n",
        "\n",
        "En la siguiente imagen se muestran las distintas estrategias.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/Introduccion/cocosp.png?raw=1\" width=\"900\">\n",
        "</center> \n",
        "\n",
        "¿Puedes identificar a que tipo de paradigma en paralelo corresponde cada imagen?."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "givB-CD7iQ4N"
      },
      "source": [
        "### Distintos Paradigmas\n",
        "\n",
        "*   Figura 1.2 (a): 2 núcleos y 2 hilos (**MPI**).\n",
        "*   Figura 1.2 (b): 1 núcleo (**Monotarea**).\n",
        "*   Figura 1.2 (c): 1 núcleos y 2 hilos (**OpenMP**).\n",
        "*   Figura 1.2 (d): 1 CPU y 1 GPU (**CUDA**).\n",
        "*   Figura 1.2 (e): recursos compartidos (**Threading**).\n",
        "\n",
        "Aunque para el programador esto no representa una gran diferencia, y estas opciones significan ejecutar al menos 2 hilos en paralelo, desde el punto de vista del hardware existen muchas diferencias de las cuales los programadores deberían estar al tanto y es por eso que surgen estándares como OpenMP, MPI y CUDA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLAv6jYtzhC0"
      },
      "source": [
        "# Cómputo en paralelo\n",
        "\n",
        "La computación en paralelo es ahora considerada una forma estándar para científicos e ingenieros para resolver problemas tan diversos como, evolución galáctica, modelado climático, diseño aeronáutico y dinámica molecular, por mencionar algunas.\n",
        "\n",
        "De tal manera que es conveniente tener en claro que significa el cómputo en paralelo y para eso es necesario tener claras las siguientes definiciones.\n",
        "\n",
        "**Cómputo en paralelo (general):**\n",
        "Es el uso de \"elementos de procesamiento\" en paralelo para reducir el tiempo empleado en resolver un problema computable.\n",
        "\n",
        "**Cómputo en paralelo:**\n",
        "Sistema de cómputo multi-procesador, que puede soportar computo en paralelo. Existen 2 categorías importantes de computadoras en paralelo, multicomputadoras (comúnmente conocidas como Cluster) y multi-procesadores centralizados.\n",
        "\n",
        "**Multi-procesadores Desentralizados (Cluster):**\n",
        "Sistema de cómputo construido con base en múltiples computadoras que se conectan a través de una red. Los procesadores en cada computadora interactúan entre si enviando y recibiendo mensajes mediante la red.\n",
        "\n",
        "**Multi-procesadores Centralizados:**\n",
        "También llamados multi-procesadores simétricos (MPS), es un sistema mas integral en el cual todos los CPU's comparten acceso a un sistema global de memoria.\n",
        "\n",
        "**Multi-procesadores de propósito específico (GPU's):**\n",
        "Sistema de computo multi-procesador, en el que el computo se realiza haciendo uso de una o mas tarjetas graficas (GPU). A diferencia de las definiciones anteriores, al emplear GPU's se considera que estos dispositivos de cómputo están optimizados para un propósito específico.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5Fe_72ybgW2"
      },
      "source": [
        "## Anatomía del CPU\n",
        "\n",
        "Para comprender más a detalle algunos de los estándares que usaremos a lo largo del seminario, es necesario analizar y comprender los componentes de la unida central de procesamiento (CPU).\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/Introduccion/lcpu.png?raw=1\" width=\"900\">\n",
        "</center> \n",
        "\n",
        "En esta imagen, dentro del **recuadro rojo** se muestra la versión de un CPU (microprocesador) con un único núcleo, los elementos que componen a este CPU son:\n",
        "\n",
        "*   **ALU**: unidad lógica-aritmética encargada de realizar operaciones (a nivel de bits) de tipo algebraicas $(+,-, *, /)$ y lógicas $(and, or, neg, equals)$.\n",
        "*   **Registros**: mecanismo de almacenamiento de bits, de acceso muy rápido, pero muy costoso, en términos monetarios.\n",
        "*   **BUS**: canal de comunicación entre el CPU y el resto del hardware.\n",
        "\n",
        "Dentro del **recuadro azul**, se muestra la arquitectura de un CPU que puede manejar hilos (hyperthreading), es decir que cuenta con una única ALU, pero se tienen 2 registros para almacenar los respectivos datos de cada hilo:\n",
        "\n",
        "*   **LCPU**: CPU lógico (virtual), se simula tener 2 CPU's completos.\n",
        "*   **BUS**: ademas de permitir la comunicación con el resto del hardware, sirve para establecer comunicación entre hilos.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/Introduccion/multicore.png?raw=1\" width=\"900\">\n",
        "</center> \n",
        "\n",
        "En la segunda imagen se muestra la arquitectura de un microprocesador Quad-core, que ademas tiene capacidades de *hyperthreading*, **4 núcleos físicos en total 8 lógicos**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYMlTe__0mcx"
      },
      "source": [
        "## Arquitecturas\n",
        "\n",
        "Existen múltiples arquitecturas de computadoras, pero las mas comunes son las siguientes\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/ComputoParalelo/SMP.png?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "En esta primer imagen se muestra una arquitectura ideal para emplear **OpenMP**.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/ComputoParalelo/cluster.png?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "En la segunda imagen se muestra una arquitectura ideal para emplear **MPI**.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/OpenMP/cuda.png?raw=1\" width=\"900\">\n",
        "</center>\n",
        "\n",
        "La última imagen corresponde a un arquitectura hybrida, idónea para **CUDA**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcg74kkG0olo"
      },
      "source": [
        "## Distintas formas de identificarlo\n",
        "\n",
        "Existen muchas formas para poder identificar si existe la posibilidad de emplear alguna técnica de paralelización.\n",
        "\n",
        "1.   **Grafica de dependencia de datos**: es un tipo de grafica dirigida en la cual cada vértice representa una tarea que debe ser realizada. Una arista del vértice u al vértice v, significa que la tarea u, debe ser realizada antes de que la tarea v comience. Se dice que ''la tarea v no es dependiente de la tarea u'' si no existe un camino de u a v por lo tanto ambas tareas son independientes y pueden ser realizadas de manera concurrente.\n",
        "2.   **Paralelizmo con datos**: una grafica de dependencia de datos muestra cuando existen tareas dependientes, unas de las otras.\n",
        "3.   **Paralelizmo funcional**: una grafica de dependencia de datos muestra paralelismo funcional cuando hay diferentes tareas aplicando diferentes operaciones a datos diferentes.\n",
        "4.   **Pipeline**: incluso cuando se tiene algún tipo de dependencia, existe la técnica del pipeline que permite generar una 'linea de ensamblaje' con la cual se pueden ejecutar multiplies procesos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exPfMdTT1qTb"
      },
      "source": [
        "# Estándares de programación\n",
        "\n",
        "De igual manera que un mecánico cuenta con diferentes herramientas dependiendo del problema, al programar en paralelo vamos a contar con diferentes estándares (API's) para poder programar en paralelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJzQim502Fp9"
      },
      "source": [
        "## OpenMP y MPI\n",
        "\n",
        "Debido a que existen múltiples arquitecturas y un sin fin de formas de implementar un algoritmo (incluso en paralelo), surgió la necesidad de crear estándares de tal manera que fuera mas sencillo poder crear algoritmos en paralelo que funcionaran en múltiples arquitecturas y que pudieran ser escalables.\n",
        " \n",
        "En este caso el termino escalable hace referencia a que una vez que se cuente con un hardware mas potente, el algoritmo definido mediante alguno de estos estándares (MPI u OpenMP), podrá ser compilado y ejecutado sin necesidad de realizar cambio alguno, y simplemente por hacer uso de hardware más potente dicho algoritmo tendrá un mejor desempeño.\n",
        "\n",
        "La principal diferencia entre OpenMP y MPI es que OpenMP se basa en el concepto de memoria compartida, mientras que MPI no contempla este requisito, sin embargo se pueden generar algoritmos híbridos, que obtengan lo mejor de ambos enfoques.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBQlLClc2U1N"
      },
      "source": [
        "### MPI\n",
        "\n",
        "MPI (Message Passing Interface) es un estándar para bibliotecas (API) que emplean el paso de mensajes como método de comunicación entre procesos. Bibliotecas de este tipo son accesible en casi cualquier sistema de computo en paralelo.\n",
        "\n",
        "Versiones gratuitas de MPI también están disponibles para desarrollo de algoritmos empleando clusters.\n",
        "\n",
        "Cada vez mas las computadoras en paralelo son construidas con base en multiprocesadores simétricos (MPS). Dentro de cada MPS el CPU tiene un espacio de memoria compartida, por lo que MPI es una forma completamente recomendable para que procesos en diferentes MPS se comuniquen entre si."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pNE1W0D2kV-"
      },
      "source": [
        "### OpenMP\n",
        "\n",
        "OpenMP al igual que MPI es un API para la programación multiproceso de memoria compartida, con la peculiaridad que puede ser empleada en múltiples plataformas debido a que es un estándar.\n",
        "\n",
        "Esta basado en el modelo fork-join (divide y vencerás), el cual propone dividir (fork) una tarea muy pesada en muchos hilos de menor complejidad, posteriormente se recolectan los resultados y finalmente se unen en un único resultado (join).\n",
        "\n",
        "Al emplear alguna directiva de compilador OpenMP, se debe especificar en que momento sincronizar los resultados del bloque en cuestión. Es decir que todo ese bloque se marca en paralelo y se ejecutaran múltiples hilos según la característica de dicha directiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CDo-OfCZkrW"
      },
      "source": [
        "## CUDA\n",
        "\n",
        "CUDA a pesar de ser un estándar de programación similar a OpenMP y MPI, difiere un poco de estos 2 debido a que el procesamiento se realiza en la unidad de procesamiento gráfico (GPU).\n",
        "\n",
        "Es necesario enviar los datos a procesar de la CPU a la GPU, se procesan los datos y se devuelven a la CPU.\n",
        "\n",
        "Podemos pensar en CUDA como una forma de programación en paralelo híbrida, ya que hace uso de ideas tanto de OpenMP como de MPI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww_YhgIG2r4s"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "1. Michaell J. Quuin: Parallel Programming in C with OpenMP and MPI.\n",
        "2. GPU Parallel Program Development Using CUDA: Tolga Soyata\n",
        "3. Referencias Libro Web: Introduccion a Python.\n",
        "4. Referencias Dongarra Foster: Source Book of parallel computing.\n",
        "5. [Diferencias CPU Físico v.s. Lógico](https://www.daniloaz.com/es/diferencias-entre-cpu-fisica-cpu-logica-core-nucleo-thread-hilo-y-socket/)."
      ]
    }
  ]
}