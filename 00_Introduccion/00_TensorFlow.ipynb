{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_TensorFlow2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/main/Introduccion/00_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKcKm7OJbfaC"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>Programación en Paralelo</i></h1>\n",
        "  <h2 align=\"center\"><i>Tensor Flow</i></h2>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M. en C. Miguel Angel Pérez León</i></h5>\n",
        "  <h5 align=\"center\"><i>Ayudante: Lucía Martínez Rivas</i></h5>\n",
        "  <h5 align=\"center\"><i>Ayudante: Erick Jesús Rios Gonzalez</i></h5>\n",
        "  <h5 align=\"center\"><i>correo: zeus@ciencias.unam.mx</i></h5>\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL3l51BpO_hL"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "*TensorFlow* es una *API* desarrollada por *Google* y es el conjunto de herramientas libres que se utiliza más ampliamente en el desarrollo de inteligencia artificial.\n",
        "\n",
        "Existen múltiples versiones de *TensorFlow*, sin embargo en esencia vamos a contar con la version 1.x y la versión 2.x. La principal diferencia entre ambas es que la versión 1.x hace uso de **grafos** para representar el flujo de los datos y la versión 2.x se apoya en [Keras](https://enmilocalfunciona.io/deep-learning-basico-con-keras-parte-1/) para generar modelos más intuitivos.\n",
        "\n",
        "En este documento nos enfocaremos en la versión 2.x de *TensorFlow* con soporte para *GPU's*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t_BRrcZMhm1"
      },
      "source": [
        "## *Tensor Flow*\n",
        "\n",
        "Existen varias formas de hacer uso de *TensorFlow*, sin embargo dadas las características del curso, nos vamos a enfocar en la forma declarativa.\n",
        "\n",
        "Lo primero que necesitamos hacer para acceder a la versión de *TensorFlow* con soporte para GPU's en Google Colab, es desinstalar la versión actual e instalar la versión con soporte para GPU's, además de cambiar el entorno de ejecución del Jupyter.\n",
        "\n",
        "1.   Para cambiar el entorno de ejecución: Primero, ir al menú *Runtime o Entorno de ejecución*, seleccionar *Cambiar tipo de tiempo de ejecución*, y en el cuadro emergente, en *Acelerador de hardware*, seleccione *GPU*, guardamos el cambio y listo.\n",
        "2.   Posteriormente validamos que se tenga acceso al *GPU*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suqiw16TkJh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d20bcd-1ea7-4b2a-bbf1-a58903815a00"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.test.is_gpu_available())\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-3a0be62431d3>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f6uXZ-6kpx8"
      },
      "source": [
        "La celda superior nos indica que tenemos acceso al GPU's y que harémos uso de la versión 2.5.0 de *TensoFlow*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZABpYxgBKIpq"
      },
      "source": [
        "### *FrameWork*\n",
        "\n",
        "Inicialmente TensorFlow fue diseñado para hacer uso de grafos para representar los datos y las operaciones que se realizan sobre los mismos. Parte de esa forma de trabajar aún funciona con la versión 2.x de *TensorFlow* y es buena idea comenzar con la misma.\n",
        "\n",
        "Como en la mayoria de *FrameWorks*, *TensorFlow* cuenta con múltiples elementos que ayudan al programador, algunos de estos elementos son:\n",
        "\n",
        "\n",
        "*   Constantes.\n",
        "*   Variables.\n",
        "*   Tensores.\n",
        "*   Escalares.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYXbD2XBKhTb"
      },
      "source": [
        "#### Operaciones\n",
        "\n",
        "Pensemos que, como parte de nuestro modelo, necesitamos procesar 2 entradas y devolver un resultado. Esta operación es muy sencilla pero muestra cómo se debe pensar en el flujo de los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0XkJHIfnB2g",
        "outputId": "e887bbf6-72d4-4db8-b304-c67f95d94810"
      },
      "source": [
        "# se realiza la suma de 3 y 5 haciendo uso de tf y del metodo add\n",
        "a = tf.add(3, 5)\n",
        "# mostramos el elemento del grafo llamado a\n",
        "print(a)\n",
        "# se muestra el resultado de la operación en el nodo a\n",
        "print(a.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1QYAfrbo7Cy"
      },
      "source": [
        "Podemos pensar en esta operación de la siguiente forma.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/sumaTF.png?raw=true\" width=\"700\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHbfmowIXru0"
      },
      "source": [
        "#### Ventaja del grafo\n",
        "\n",
        "El grafo nos da la ventaja de construir de manera organizada y visual la forma en la que se procesan los datos.\n",
        "\n",
        "Ahora pensemos que deseamos realizar la siguiente operación.\n",
        "\n",
        "$$\\left(2\\times3\\right)^{\\left(2+5\\right)}$$\n",
        "\n",
        "¿Cómo se vería este grafo y cómo se escribe esta operación con *TensorFlow*?.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/powTF.png?raw=true\" width=\"700\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im0VZhAlrO_F",
        "outputId": "c505590b-76fd-480a-916e-e31752363878"
      },
      "source": [
        "# Variables de Python\n",
        "x = 2\n",
        "y = 3\n",
        "\n",
        "# Operaciones y grafo de TensorFlow\n",
        "op1 = tf.add(x, y)\n",
        "op2 = tf.multiply(x, y)\n",
        "op3 = tf.pow(op2, op1)\n",
        "\n",
        "# Veamos el nodo op3\n",
        "print(op3)\n",
        "\n",
        "# El resultado de dicha operación es\n",
        "print(op3.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(7776, shape=(), dtype=int32)\n",
            "7776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_Ym3FtKRP1t"
      },
      "source": [
        "#### Red Neuronal\n",
        "\n",
        "Conforme vamos agregando más nodos al grafo, este cada vez se parece más a una red, incluso podemos llegar a un punto en el cual el grafo sea similar a una red neuronal.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/som.gif?raw=true\" width=\"700\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nKaftH_QgXy"
      },
      "source": [
        "### Acceso a la *GPU*\n",
        "\n",
        "En la sección anterior vimos que ya se contaba con acceso a la *GPU*, ahora vamos a ver qué tan buena idea es hacer uso de la misma.\n",
        "\n",
        "Vamos a definir 2 métodos que hagan uso de *TensorFlow*, uno de ellos procesando los datos en la *CPU* y el otro en la *CPU*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCR8gKF2Q70u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de785268-24f6-47a2-abef-257a6fffd4a4"
      },
      "source": [
        "# Biblioteca para medir el tiempo\n",
        "import timeit\n",
        "\n",
        "# Validamos que se tenga acceso a la GPU de google colab\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print(\n",
        "        '\\n\\nNo se tiene habilitado el acceso a la GPU, revisa la configuracion '\n",
        "        'del notebook.\\n\\n')\n",
        "    raise SystemError('No se cuenta con GPU')\n",
        "\n",
        "# Metodo que realiza el reduce en la CPU de los valores aleatorios de una matriz\n",
        "def cpu():\n",
        "    # con esta linea se procesa el bloque en la CPU\n",
        "    with tf.device('/cpu:0'):\n",
        "      # generamos una matriz de 100x100x100 con valore aleatorios entre (0,1)\n",
        "      random_image_cpu = tf.random.normal((100, 100, 100))\n",
        "      # mediante tensorflow se realiza el reduce y se devuelve un valor\n",
        "      return tf.math.reduce_sum(random_image_cpu).numpy()\n",
        "\n",
        "# Metodo que realiza el reduce en la GPU de los valores aleatorios de una matriz\n",
        "def gpu():\n",
        "    # con esta linea se procesa el bloque en la GPU\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      # generamos una matriz de 100x100x100 con valore aleatorios entre (0,1)\n",
        "      random_image_gpu = tf.random.normal((100, 100, 100))\n",
        "      # mediante tensorflow se realiza el reduce y se devuelve un valor\n",
        "      return tf.math.reduce_sum(random_image_gpu)\n",
        "\n",
        "# Provemos ambos metodos\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Se ejecutan ambos algoritmos 10 veces y se muestran los respectivos tiempos\n",
        "print('Se muestra la suma del tiempo de haber ejecutado estos algoritmos '\n",
        "      '10 veces.')\n",
        "# Seccion para la CPU\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "# Seccion para la GPU\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "# Mejora en el tiempo de la GPU respecto a la CPU\n",
        "print('Mejora en el tiempo de ejecucion de GPU '\n",
        "      'v.s. CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se muestra la suma del tiempo de haber ejecutado estos algoritmos  10 veces.\n",
            "CPU (s):\n",
            "0.18778029899999638\n",
            "GPU (s):\n",
            "0.004059490999992477\n",
            "Mejora en el tiempo de ejecucion de GPU v.s. CPU: 46x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOr5r_Zfdzg4"
      },
      "source": [
        "### Aplicaciones\n",
        "\n",
        "El ejemplo anterior solo muestra una pequeña parte de un algoritmo en la cual se puede mejorar en gran medida el desempeño de una red neuronal mediate *TensorFlow* en su versión para *GPU's*.\n",
        "\n",
        "En gran medida las operaciones dentro de una red neuronal (y en general en el aprendizaje de máquina) pueden ser mejoradas mediante el uso de los *GPU's* disponibles.\n",
        "\n",
        "En la celda anterior se puede ver de manera clara el por qué el uso de TensorFlow se ha vuelto tan popular, sin embargo no olivdemos que muchos de los procesos llevados a cabo quedan ocultos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvWHgFw737PR"
      },
      "source": [
        "## Red Neuronal al instante\n",
        "\n",
        "Vamos a 'construir' una red neuronal en un par de celdas mediante *TensorFlow*, el código e imágenes mostradas a continuación se toman del [manual oficial](https://www.tensorflow.org/tutorials/keras/classification?hl=es-419) de *TensorFlow*.\n",
        "\n",
        "En este ejemplo vamos a mostrar y entrenar una red neuronal que pueda clasificar imágenes de prendas.\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/fashion-mnist-sprite.png?raw=true\" width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FijLghcNljSW"
      },
      "source": [
        "### *MNIST*\n",
        "\n",
        "Dado que esta red neuronal clasifica imágenes de ropa, necesitamos una **base de datos** grande de estas imágenes.\n",
        "\n",
        "*MNIST* es una base de datos accesible mediante la red y con una gran cantidad de datos para entrenar nuestras redes neuronales.\n",
        "\n",
        "Así que el primer paso es cargar esta base de datos en la sesión actual de *google colab*, esto se realiza en la siguiente celda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJHBg6gBmjbE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998f4eca-3b0a-4126-82a0-df5376b0a6b3"
      },
      "source": [
        "# TensorFlow y tf.keras\n",
        "from tensorflow import keras\n",
        "\n",
        "# Librerias de ayuda\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "26435584/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxUYelrUm5ma"
      },
      "source": [
        "Al ejecutar la celda anterior vamos a tener en memoria cuatro arreglos en *NumPy*:\n",
        "\n",
        "* Los arreglos *train_images* y *train_labels* son los arreglos que conforman el *training set* y que usa el modelo de datos para aprender/entrenar.\n",
        "* El modelo es probado contra los arreglos *test_images*, y *test_labels* que conforman el *test set*.\n",
        "\n",
        "Las imágenes son arreglos de *NumPy* (matrices) de 28x28, con valores en cada entrada (píxeles) que varian de 0 a 255. Los *labels* es un arreglo de enteros, que van del 0 al 9. Estos corresponden a la *class* de ropa que la imagen representa.\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Etiqueta</th>\n",
        "    <th>Clase</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>Palyera/blusa</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trusa</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Vestido</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Abrigo</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandalia</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Camisa</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bolsa</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Bota al tobillo</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Dado que los nombres de las clases (Class name) no vienen incluidos en la información que recién descargamos, es necesario almacenarlos en una variable de *Python*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lP9hwfAp_Fu"
      },
      "source": [
        "class_names = ['Camiseta/Blusa', 'Trusa', 'Pullover', 'Vestido', 'Abrigo',\n",
        "               'Sandalia', 'Camisa', 'Sneaker', 'Bolsa', 'Bota al tobillo']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVnJfA_6qeqm"
      },
      "source": [
        "#### Contenido del *data set*\n",
        "\n",
        "El contenido del set de datos antes de entrenar el modelo es el siguiente, hay 60,000 imagenes en el set de entrenamiento, con cada imagen representada por mapas de bits (matrices) de 28x28:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFPXz_Aiq-pj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d6fd10-4e9d-45b8-a7a3-223ad06ece77"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebocVnUsr1cf"
      },
      "source": [
        "Se cuenta con 60,000 etiquetas para el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22SU3xl0rDN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38483df7-938f-4f71-b98b-de1992ee14d6"
      },
      "source": [
        "len(train_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba0eVgKAr83I"
      },
      "source": [
        "Cada etiqueta es un entero entre $0-9$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipXt0FNiroMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28599674-5190-4fb7-d04c-977ff69f6e46"
      },
      "source": [
        "train_labels\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuZrBSnWsHlE"
      },
      "source": [
        "Hay 10,000 imagenes en el set de pruebas. Otra vez, cada imagen es representada como arreglos de *numpy* (matrices) de 28x28:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGVfefESrrMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d155f6-3adb-464c-c597-8f1e76a62d50"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg7pcPFGsULr"
      },
      "source": [
        "Finalmente el conjunto de pruebas cuenta con 10,000 etiquetas para el momento de validar la efectividad del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5deznVXruXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59fa032-88d6-4181-f680-b877829a4407"
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZjncGY-sn73"
      },
      "source": [
        "### Preprocesando los datos\n",
        "\n",
        "Es frecuente al hacer uso de imágenes, que estas requieran un \"preprocesamiento\" antes de ser utilizadas por el modelo.\n",
        "\n",
        "Veamos la primer imagen del conjunto de imágenes y comprobemos que son imágenes de 28x28 pixeles y cada pixel toma un valor en el rango entre $0-255$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGlEQuAPsrg1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "4dc53f5e-9a42-48a1-9dfa-171b59aa5a10"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5dd9cbda4ed0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R5cGaazt7g0"
      },
      "source": [
        "Es necesario escalar los valores de las imágenes en un rango de $0$ a $1$ antes de alimentarlos al modelo de la red neuronal. Para hacero, es necesario dividir los valores por $255$. Es importante que el *training set* y el *testing set* se pre-procesen de la misma forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JRPByNjuNkO"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMgO4P_JuSFN"
      },
      "source": [
        "Para verificar que el set de datos esta en el formato adecuado y que estan listos para construir y entrenar la red, vamos a desplegar las primeras 25 imagenes de el *training set* y despleguemos el nombre de cada clase debajo de cada imagen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "856-vc-juTOz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "52fffbd9-df3f-44e1-8ad8-d0a9f12f2db3"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-54389fd111e2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LQv5RR4u3jf"
      },
      "source": [
        "### Contruir el modelo\n",
        "\n",
        "El modelo de esta red neuronal es un modelo por capas como el que podemos ver en la siguiente imagen.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/reco_ropa.png?raw=true\" width=\"700\">\n",
        "</center>\n",
        "\n",
        "Existe todo un marco teórico detras de la construcción de este modelo y para mayor detalle se invita a revisar las referencias. En esta sección vamos a mostrar el código necesario y una breve explicación del mismo.\n",
        "\n",
        "En la siguiente celda se genera el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU-ELd-KynTS",
        "outputId": "d01f7070-d750-465b-f54b-994e01ca09e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'keras' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d190941ea79a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = keras.Sequential([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h0Xtlagy2BF"
      },
      "source": [
        "La primera capa de esta red, `tf.keras.layers.Flatten`,\n",
        "transforma el formato de las imágenes de un arreglo bi-dimensional (de 28 por 28 píxeles) a un arreglo uni dimensional (de 28x28 píxeles = 784 píxeles). Observe esta capa como una capa no apilada de filas de píxeles, pensemos que la imagen que \"aplana\" (*flatten*) en una sola fila. Esta capa no tiene parámetros que aprender; solo reformatea el set de datos.\n",
        "\n",
        "Despues de que los píxeles estan \"aplanados\", la secuencia consiste de dos capas`tf.keras.layers.Dense`. Ambas capas estan densamente conectadas, o completamente conectadas. La primera capa `Dense` tiene 128 nodos (o neuronas). La segunda (y última) capa es una capa de 10 nodos *softmax* que devuelve un arreglo de 10 probabilidades que suman a 1. Cada nodo contiene una calificación que indica la probabilidad que la actual imagen pertenece a una de las 10 clases.\n",
        "\n",
        "Otro de los parámetros que reciben las capas son las **funciones de activación** (*relu* y *softmax*). Estas funciones de activación son elementos fundamentales en el diseño de una red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQE4o7szz3Oj"
      },
      "source": [
        "### Compilando el modelo\n",
        "\n",
        "Antes de que el modelo este listo para entrenar , se necesitan algunas configuraciones más. Estas son agregadas durante el paso de compilación del modelo:\n",
        "\n",
        "* *Loss function*: También conocida como función de costos, mide que tan exacto es el modelo durante el entrenamiento. La idea es minimizar esta función para dirigir el modelo en la dirección adecuada.\n",
        "* *Optimizer*: Mediante el optimizador es como el modelo se actualiza basado en el set de datos que ve y la evaluación de la función de costos. Uno de los optimizadores que se usan de manera más frecuente es el **descenso del gradiente**.\n",
        "* *Metrics*: Se usan para monitorear los pasos de entrenamiento y de pruebas.\n",
        "\n",
        "El siguiente ejemplo usa *accuracy* (exactitud), es decir la fracción de la imágenes que son correctamente clasificadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSk5xyYC5Oz3"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_YTb7Jb5m8I"
      },
      "source": [
        "### Entrenar el modelo\n",
        "\n",
        "Entrenar el modelo de red neuronal requiere de los siguientes pasos:\n",
        "\n",
        "1. Entregue los datos de entrenamiento al modelo. En este ejemplo , el set de datos de entrenamiento estan en los arreglos `train_images` y `train_labels`.\n",
        "2. El modelo aprende a asociar imagenes y etiquetas.\n",
        "3. Usted le pregunta al modelo que haga predicciones sobre un set de datos que se encuentran en el ejemplo, incluido en el arreglo `test_images`. Resta verificar que las predicciones sean iguales a las etiquetas de el arreglo`test_labels`.\n",
        "\n",
        "Para comenzar a entrenar, llame el metodo `model.fit`, es llamado asi por que *fit* (ajusta) el modelo a el set de datos de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GinjX0sK5tIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12dc9775-5317-4c8b-94e9-3c06bab8978f"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 2ms/step - loss: 0.4975 - accuracy: 0.8260\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3763 - accuracy: 0.8644\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3369 - accuracy: 0.8771\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3121 - accuracy: 0.8854\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2954 - accuracy: 0.8917\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2815 - accuracy: 0.8959\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2681 - accuracy: 0.9011\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2582 - accuracy: 0.9037\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2461 - accuracy: 0.9080\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2378 - accuracy: 0.9107\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f96e1065e90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGo1n7_n58jM"
      },
      "source": [
        "### Interpretando imágenes\n",
        "\n",
        "Se le muestra un conjunto de imagenes al modelo `test_images` y el modelo nos devuelve un una lista `prediccion` que nos indica que es lo que interpreta el modelo de la imágen en cada una de sus entradas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSX5fcmg6Rz_"
      },
      "source": [
        "predicciones = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQfOxejN5-nv"
      },
      "source": [
        "# FUNCIONES AUXILIARES PARA GRAFICAR\n",
        "# grafica una imagen y su respectiva prediccion por el modelo\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "# muestra la probabilidad que indica el modelo de cada prenda de ropa\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXyWr2qCxx5O"
      },
      "source": [
        "Veamos que interpretación le da el modelo a la imágen 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da2WeX_N6Lfo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5b2d6afa-d42a-4ed6-966f-76b43576d0b2"
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predicciones[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predicciones[i],  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIAc6Iocx_ie"
      },
      "source": [
        "Y veamos ahora que sucede con la imágen 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7ri9WE_6bYQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f4a523ca-10e0-4b16-898c-9a463ddfb472"
      },
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predicciones[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predicciones[i],  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAh_UjLcaKr7"
      },
      "source": [
        "## Referencias\n",
        "\n",
        "*   https://www.tensorflow.org/tutorials/keras/classification?hl=es-419\n",
        "*   http://www.saedsayad.com/clustering_som.htm\n",
        "*   https://www.tensorflow.org/install\n",
        "*   https://codesachin.wordpress.com/2015/11/28/self-organizing-maps-with-googles-tensorflow/\n",
        "\n"
      ]
    }
  ]
}