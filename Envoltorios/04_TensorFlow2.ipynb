{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Envoltorios/04_TensorFlow2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKcKm7OJbfaC"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>TensorFlow</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M. en C. Miguel Angel Pérez León</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Mario Arturo</i></h5>\n",
        "  <h5 align=\"center\"><i>Materia: Seminario de programación en paralelo</i></h5>\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL3l51BpO_hL"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "*TensorFlow* es una *API* desarrollado por *Google* y es el conjunto de herramientas libres que se utiliza más ampliamente en el desarrollo de inteligencia artificial.\n",
        "\n",
        "Existen multiples versiones de *TensorFlow*, sin embargo en escencia vamos a contar con la version 1.x y la versión 2.x. La principal diferencia entre ambas es que la versión 1.x hace uso de **grafos** para representar el flujo de los datos y la versión 2.x se apoya en [Keras](https://enmilocalfunciona.io/deep-learning-basico-con-keras-parte-1/) para generar modelos más intuitivos.\n",
        "\n",
        "En este documento nos enfocaremos en la versión 2.x de *TensorFlow* con soporte para *GPU's*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t_BRrcZMhm1"
      },
      "source": [
        "## *Tensor Flow*\n",
        "\n",
        "Existen varias formas de hacer uso de *TensoFlow*, sin embargo dadas las características del curso, nos vamos a enfocar en la forma declarativa.\n",
        "\n",
        "Lo primero que necesitamos hacer para acceder a la versión de *TensorFlow* con soporte para GPU's en Google Colab, es desinstalar la versión actual e instalar la versión con soporte para GPU's, además de cambiar el entorno de ejecución del jupyter.\n",
        "\n",
        "1.   Para cambiar el entorno de ejecución: Primero, ir al menú *Runtime o Entorno de ejecución*, seleccionar *Cambiar tipo de tiempo de ejecución*, y en el cuadro emergente, en *Acelerador de hardware*, seleccione *GPU*, guardamos el cambio y listo.\n",
        "2.   Posteriormente validamos que se tenga acceso al *GPU*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suqiw16TkJh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55e571d-9a6e-40b5-b19f-eaf6307ec1af"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.test.is_gpu_available())\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-3a0be62431d3>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "True\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f6uXZ-6kpx8"
      },
      "source": [
        "La celda superior nos indica que tenemos acceso al GPU's y que harémos uso de la versión 2.5.0 de *TensoFlow*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZABpYxgBKIpq"
      },
      "source": [
        "### *FrameWork*\n",
        "\n",
        "Inicialmente TensorFlow fue diseñado para hacer uso de grafos para representar los datos y las operaciones que se realizan sobre los mismos. Parte de esa forma de trabajar aun funciona con la versión 2.x de *TensorFlow* y es buena idea comenzar con la misma.\n",
        "\n",
        "Como en la mayoria de *FrameWorks*, *TensorFlow* cuenta con multiples elementos que ayudan al programador, algunos de estos elementos son:\n",
        "\n",
        "\n",
        "*   Constantes.\n",
        "*   Variables.\n",
        "*   Tensores.\n",
        "*   Escalares.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYXbD2XBKhTb"
      },
      "source": [
        "#### Operaciones\n",
        "\n",
        "Pensemos que, como parte de nuestro modelo necesitamos procesar 2 entradas y devolver un resultado. Esta operación es muy sencilla pero muestra como se debe pensar en el flujo de los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0XkJHIfnB2g",
        "outputId": "e887bbf6-72d4-4db8-b304-c67f95d94810"
      },
      "source": [
        "# se realiza la suma de 3 y 5 haciendo uso de tf y del metodo add\n",
        "a = tf.add(3, 5)\n",
        "# mostramos el elemento del grafo llamado a\n",
        "print(a)\n",
        "# se muestra el resultado de la operación en el nodo a\n",
        "print(a.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1QYAfrbo7Cy"
      },
      "source": [
        "Podemos pensar en esta operación de la siguiente forma.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/sumaTF.png?raw=true\" width=\"700\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHbfmowIXru0"
      },
      "source": [
        "#### Ventaja del grafo\n",
        "\n",
        "El grafo nos da la ventaja de construir de manera organizada y visual la forma en la que se procesan los datos.\n",
        "\n",
        "Ahora pensemos que deseamos realizar la siguiente operación. \n",
        "\n",
        "$$\\left(2\\times3\\right)^{\\left(2+5\\right)}$$\n",
        "\n",
        "¿Cómo se vería este grafo y cómo se escribe esta operación con *TensorFlow*?.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/powTF.png?raw=true\" width=\"700\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im0VZhAlrO_F",
        "outputId": "c505590b-76fd-480a-916e-e31752363878"
      },
      "source": [
        "# Variables de Python\n",
        "x = 2\n",
        "y = 3\n",
        "\n",
        "# Operaciones y grafo de TensorFlow\n",
        "op1 = tf.add(x, y)         \n",
        "op2 = tf.multiply(x, y)    \n",
        "op3 = tf.pow(op2, op1)\n",
        "\n",
        "# Veamos el nodo op3\n",
        "print(op3)\n",
        "\n",
        "# El resultado de dicha operación es\n",
        "print(op3.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(7776, shape=(), dtype=int32)\n",
            "7776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_Ym3FtKRP1t"
      },
      "source": [
        "#### Red Neuronal\n",
        "\n",
        "Conforme vamos agregando más nodos al grafo, este cada vez se parece más a una red, incluso podemos llegar a un punto en el cual el grafo sea similar a una red neuronal.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/som.gif?raw=true\" width=\"700\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nKaftH_QgXy"
      },
      "source": [
        "### Acceso a la *GPU*\n",
        "\n",
        "En la sección anterior vimos que ya se contaba con acceso a la *GPU*, ahora vamos a ver que tan buena idea es hacer uso de la misma.\n",
        "\n",
        "Vamos a definir 2 métodos que hagan uso de *TensorFlow*, uno de ellos procesando los datos en la *CPU* y el otro en la *CPU*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCR8gKF2Q70u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de785268-24f6-47a2-abef-257a6fffd4a4"
      },
      "source": [
        "# Biblioteca para medir el tiempo\n",
        "import timeit\n",
        "\n",
        "# Validamos que se tenga acceso a la GPU de google colab\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print(\n",
        "        '\\n\\nNo se tiene habilitado el acceso a la GPU, revisa la configuracion '\n",
        "        'del notebook.\\n\\n')\n",
        "    raise SystemError('No se cuenta con GPU')\n",
        "\n",
        "# Metodo que realiza el reduce en la CPU de los valores aleatorios de una matriz\n",
        "def cpu():\n",
        "    # con esta linea se procesa el bloque en la CPU\n",
        "    with tf.device('/cpu:0'):\n",
        "      # generamos una matriz de 100x100x100 con valore aleatorios entre (0,1)\n",
        "      random_image_cpu = tf.random.normal((100, 100, 100))\n",
        "      # mediante tensorflow se realiza el reduce y se devuelve un valor\n",
        "      return tf.math.reduce_sum(random_image_cpu).numpy()\n",
        "\n",
        "# Metodo que realiza el reduce en la GPU de los valores aleatorios de una matriz\n",
        "def gpu():\n",
        "    # con esta linea se procesa el bloque en la GPU\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      # generamos una matriz de 100x100x100 con valore aleatorios entre (0,1)\n",
        "      random_image_gpu = tf.random.normal((100, 100, 100))\n",
        "      # mediante tensorflow se realiza el reduce y se devuelve un valor\n",
        "      return tf.math.reduce_sum(random_image_gpu)\n",
        "  \n",
        "# Provemos ambos metodos\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Se ejecutan ambos algoritmos 10 veces y se muestran los respectivos tiempos\n",
        "print('Se muestra la suma del tiempo de haber ejecutado estos algoritmos '\n",
        "      '10 veces.')\n",
        "# Seccion para la CPU\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "# Seccion para la GPU\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "# Mejora en el tiempo de la GPU respecto a la CPU\n",
        "print('Mejora en el tiempo de ejecucion de GPU '\n",
        "      'v.s. CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se muestra la suma del tiempo de haber ejecutado estos algoritmos  10 veces.\n",
            "CPU (s):\n",
            "0.18778029899999638\n",
            "GPU (s):\n",
            "0.004059490999992477\n",
            "Mejora en el tiempo de ejecucion de GPU v.s. CPU: 46x\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOr5r_Zfdzg4"
      },
      "source": [
        "### Aplicaciones\n",
        "\n",
        "El ejemplo anterior solo muestra una pequeña parte de un algoritmo en la cual se puede mejorar en gran medida el desempeño de una red neuronal mediate *TensorFlow* en su versión para *GPU's*.\n",
        "\n",
        "En gran medida las operaciones dentro de una red neuronal (y en general en el aprendizaje de máquina) pueden ser mejoradas mediante el uso de los *GPU's* disponibles.\n",
        "\n",
        "En la celda anterior se puede ver de manera clara el por qué el uso de TensorFlow se ha vuelto tan popular, sin embargo no olivdemos que muchos de los procesos llevados a cabo quedan ocultos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvWHgFw737PR"
      },
      "source": [
        "### Red Neuronal al instante\n",
        "\n",
        "Vamos a 'construir' una red en una celda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAh_UjLcaKr7"
      },
      "source": [
        "## Referencias\n",
        "\n",
        "*   https://codesachin.wordpress.com/2015/11/28/self-organizing-maps-with-googles-tensorflow/\n",
        "*   http://www.saedsayad.com/clustering_som.htm\n",
        "*   https://www.tensorflow.org/install\n",
        "*   https://relopezbriega.github.io/blog/2016/06/05/tensorflow-y-redes-neuronales/\n",
        "\n"
      ]
    }
  ]
}