{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ley Amdahl.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Introduccion/08_Ley_Amdahl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sobre manejo de memoria\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3tU5QG_gsQrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recordemos que trabajar con *OpenMP* es trabajar bajo el modelo *PRAM* (Parallel Random Access Machine), es decir, que tenemos varios procesadores con acceso a un segmento de memoria en común, sin embargo, al trabajar varios datos a la vez hay que cuidar el manejo y acceso a la memoria. Una ventaja es que no hay límite en los números de procesadores para nuestro modelo, más que el costo económico que esto pudiera ocasionar. \n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/tree/main/Imagenes/Introduccion/MemShare.png\" width=\"400\"> \n",
        "</center>\n",
        "\n",
        "Existen varias formas de manipular la memoria compartida, son los siguientes: \n",
        "\n",
        "\n",
        "*   EREW (**E**xclusive **R**ead **E**xclusive **W**rite)\n",
        "*   CREW (**C**oncurrent **R**ead **E**xclusive **W**rite)\n",
        "*   CRCW (**C**oncurrent **R**ead **C**oncurrent **W**rite)\n",
        "\n",
        "Queda como ejercicio al lector, pensar en que problemas se deben o pueden utilizar las diferentes formas de acceder a la información.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5i4rV9iNsQOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taxonomía de Flynn"
      ],
      "metadata": {
        "id": "OupnFho40IUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La taxonomía de Flynn es una clasificación para arquitecturas paralelas, la clasificación fue creada por Michael J. Flynn, la cual clasifica por la cantidad de intrucciones y flujo de datos. \n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/tree/main/Imagenes/Introduccion/Flynn.png\" width=\"400\"> \n",
        "</center>\n",
        "\n",
        "*  SISD *(Single Instruction Single Data)*\n",
        "*  MISD *(Multiple Instruction Single Data)*\n",
        "*  SIMD *(Single Instruction Multiple Data)* \n",
        "*  MIMD *(Multiple Instruction Multiple Data)* \n",
        "\n",
        "Esta última es muy usada para explotar el paralelismo, ya sea con memoria distribuida y memoria compartida o un hibrido como son los clúsers. \n",
        "\n"
      ],
      "metadata": {
        "id": "2HDxXraE50jY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aceleración, eficiencia y fracción serial "
      ],
      "metadata": {
        "id": "xic0uJvY89DI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$T(n,1)$ es la complejidad en tiempo del mejor algoritmo secuencial, el número uno indica que solo se esta usando un hilo. \n",
        "\n",
        "$T(n,p)$ es la complejidad en tiempo del algoritmo paralelo usando $p$ procesadores. \n",
        "\n",
        "Existen tres métricas que nos interesan y son: la ***aceleración (Speedup)***, la ***eficiencia*** y la ***fracción serial***\n",
        "\n",
        "Em motivo principal para usar un algoritmo paralelo es *acelerar* los cálculos secuenciales. Es por ello que nos interesa conocer la aceleración:  \n",
        "\n",
        "$$S(p) = \\frac{T(n,1)}{T(n,p)} $$\n",
        "\n",
        "Entonces, la ***aceleración*** mide cuántas veces más rápido es el algoritmo paralelo, el valor ideal es $p$.\n",
        "\n",
        "La ***eficiencia*** mide que tan eficientemente se están utilizanda los procesadores y el valor ideal es $1$, se calcula de la siguiente forma: \n",
        "\n",
        "$$E(p) = \\frac{S(p)}{p} $$\n",
        "\n",
        "Es decir, la aceleración entre el número de procesadores.\n",
        "\n",
        "La ***fracción serial*** mide la parte del código que es inherentemente secuencial y el valor ideal es $0$.\n",
        "\n",
        "$$ F(p) = \\frac{\\frac{1}{S(p)} -\\frac{1}{p}}{1 - \\frac{1}{p}} $$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iAWYJUUcvl7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codigo = \"\"\"\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <sys/time.h>\n",
        "#include <omp.h>\n",
        "\n",
        "\n",
        "int main(int argc, char** argv){\n",
        "\n",
        "    // Se valida que se haya pasado el parámetro \n",
        "\n",
        "\tlong int suma = 0;\n",
        "    long int suma_p = 0; \n",
        "    long int sumaHilo = 0; \n",
        "    double inicio_s, fin_s, inicio_p, fin_p; // Para los tiempos de ejecución\n",
        "\n",
        "    inicio_s = omp_get_wtime();\n",
        "\tfor(int i =0; i <= 1000000000; i++){\n",
        "\t\tsuma = suma +i;\n",
        "\t}\n",
        "    fin_s = omp_get_wtime();\n",
        "    double tiempo_s = fin_s - inicio_s;\n",
        "\tprintf(\"suma: %li  \\\\n tiempo de ejecucion: %f \\\\n\",suma, fin_s - inicio_s); //imprime resultados\n",
        "\n",
        "    inicio_p = omp_get_wtime();\n",
        "\n",
        "    int numHilos;\n",
        "    sscanf(argv[1], \"%i\", &numHilos);\n",
        "\n",
        "   \tomp_set_num_threads(numHilos);\n",
        "\tint idHilo; \n",
        "\t//inicia seccion paralela\n",
        "\t#pragma omp parallel private(idHilo, sumaHilo)\n",
        "    {\n",
        "\t\tidHilo = omp_get_thread_num();\n",
        "\t\tif (idHilo==0){\n",
        "\t\t\tprintf (\"iniciando calculo con %i hilos\\\\n\", omp_get_num_threads());\n",
        "\t\t}\n",
        "\t\t\n",
        "\t\t//cada hilo realiza una suma parcial\n",
        "\t\tsumaHilo=0;\n",
        "\t\tint i;\n",
        "\t\tfor (i=idHilo;i<=1000000000;i+=numHilos){\n",
        "\t\t\tsumaHilo+=i;\n",
        "\t\t}\n",
        "\t\t\n",
        "\t\t//cada hilo actualiza la suma total con su resultado parcial\n",
        "\t\tsuma_p+=sumaHilo;\n",
        "\t}//fin de seccion paralela\n",
        "\n",
        "\n",
        "    fin_p = omp_get_wtime();\n",
        "    double tiempo_p=  fin_p - inicio_p;\n",
        "\tprintf(\"suma paralela: %li  \\\\n Tiempo de ejecucion algoritmo paralelo: %f \\\\n\",suma,tiempo_p);\n",
        "  double aceleracion = tiempo_s/tiempo_p;\n",
        "  printf(\"La aceleración de paralelizar la suma se los primeros 1 000 000 000 número naturales es: %f \\\\n\", aceleracion);\n",
        "  double eficiencia = aceleracion/2;\n",
        "  printf(\"La eficiencia es: %f tomando que la prueba en colab se hace en dos procesadores \\\\n\", eficiencia);\n",
        "\n",
        "}\n",
        "\"\"\" "
      ],
      "metadata": {
        "id": "XsGZA4xg6sPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# se crea el archivo con permisos para escribir mediante python\n",
        "archivo_texto = open(\"sumaIntervalo.c\", \"w\")\n",
        "# se escribe el programa en el archivo \n",
        "archivo_texto.write(codigo)\n",
        "# se cierra el buffer de escritura\n",
        "archivo_texto.close()"
      ],
      "metadata": {
        "id": "ZvWAs7OyhW0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcc -o suma -fopenmp sumaIntervalo.c"
      ],
      "metadata": {
        "id": "mWRdPiH5hefY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./suma 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH-OhfgfhfC_",
        "outputId": "917029a7-9cde-41ff-f9f5-ad4eab027ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "suma: 500000000500000000  \n",
            " tiempo de ejecucion: 3.297801 \n",
            "iniciando calculo con 2 hilos\n",
            "suma paralela: 500000000500000000  \n",
            " Tiempo de ejecucion algoritmo paralelo: 2.163480 \n",
            "La aceleración de paralelizar la suma se los primeros 1 000 000 000 número naturales es: 1.524304 \n",
            "La eficiencia es: 0.762152 tomando que la prueba en colab se hace en dos procesadores \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Queda como ejercicio al lector calcular la fracción serial e interpretar el resultado. ⚡\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "huf_osurzibX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXKB7jMp9q_I",
        "outputId": "174e9183-9540-4d52-b227-26c0306f8770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2199.998\n",
            "BogoMIPS:            4399.99\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "¿Qué es lo que debe tomarse en cuenta cuando se hacen este tipo de pruebas? \n",
        "\n",
        "* Procesos en segundo plano ejecutando\n",
        "* Las condiciones en las que se encuentra el equipo\n",
        "* Recursos compartidos on otras aplicaciones, por ejemplo, *Mozilla*, *Spotify* entre otras..."
      ],
      "metadata": {
        "id": "7NXG66CK-M_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ley de Amdahl \n",
        "\n",
        "El objetivo principal de usar un algoritmo paralelo es obtener los resultados lo más pronto posible, es decir, disminuir la complejidad en tiempo. Al aumentar el número de procesadores en el sistema paralelo se distribuyen las sub-tares entre los procesadores. Sin embargo, surge la pregunta ¿Siempre que aumente el número de procesadores disminuirá el tiempo de ejecución? \n",
        "\n",
        "Resulta que la ley de Amdahl dice que llega un punto en el cual sin importar que el numero de procesadores sea muy alto , el speedup se va a comportar de manera lineal. Dicho de otra forma cada sección paralelizable de un algoritmo tendrá un número $n$ de procesadores optimos, si ejecutamos el algoritmo con más de $n$ procesadores no mejorará el tiempo de ejecución.\n",
        "\n"
      ],
      "metadata": {
        "id": "JsEyeevk6kLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/tree/main/Imagenes/Introduccion/LeyAmdahl.png\" width=\"400\"> \n",
        "</center>"
      ],
      "metadata": {
        "id": "uGvii3oH-o8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La gráfica anterior nos muestra que dependiendo del porcentaje de código ejecutado de manera paralela será la cota de número de procesadores para alcanzar la máximo eficiencia. "
      ],
      "metadata": {
        "id": "EbcAEt45_cku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/tree/main/Imagenes/Introduccion/LeyATime.png\" width=\"400\"> \n",
        "</center>"
      ],
      "metadata": {
        "id": "-cyXdBLLWV-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### La ley de Amdahl en suma paralela\n",
        "\n",
        "En el siguiente cuadro de datos tenemos algunas ejecuciones de pruebas realizadas en una computadora con las siguientes carácteristicas, se obtuvo un tiempo de ejecución de: 3 255 980 microsegundos\n",
        "\n",
        "* Marca *Dell*\n",
        "* Intel(R) Core(TM) i5-6300U CPU 2.40 GHz \n",
        "* 4 CPU's  \n",
        "* 16 Gb de RAM\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/tree/main/Imagenes/Introduccion/SumaParalelaLDA.png\" width=\"400\">\n",
        "</center>\n",
        "\n",
        "Observemos que en el Cuadro el mejor tiempo ($1107980{.}8 \\mu s$) que se presenta es cuando el programa usa únicamente 4 hilos, la computadora donde se ejecutaron las pruebas es una Dell con 4 CPU(s). En el cuadro tenemos que los mejores tiempos obtenidos corresponden al renglón de las pruebas realizadas con 50 hilos. Incluso podemos observar que los mejores tiempos corresponden a las pruebas realizadas con 50 hilos. Recordemos que cualquier problema tiene una cota en tiempo óptimo, además también hay una cota para el número de procesadores que pueden optimizar un proceso. Cada problema tendrá un número de hilos óptimo, para este caso tenemos que 50 hilos nos proporciona el tiempo óptimo, al usar 100 aumentamos el tiempo en vez de disminuirlo, se tendría que buscar el número $n$ donde se pierde la optimización del problema. "
      ],
      "metadata": {
        "id": "F2UfClz4ZrID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CqpdG1XDbT1E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}