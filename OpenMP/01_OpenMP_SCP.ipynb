{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenMP_SCP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/main/OpenMP/OpenMP_SCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBC0NKmEENHP"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>OpenMP (memoria compartida)</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M.en.C. Miguel Angel Pérez León</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Mario Arturo Nieto Butron</i></h5>\n",
        "  <h5 align=\"center\"><i>Materia: Seminario de programación en paralelo</i></h5>\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK0VO6YaG_Du"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "Aun en la década de los 80's adquirir una computadora con múltiples procesadores era costoso, incluso actualmente el precio de una computadora depende en gran medida del numero de procesadores que tenga.\n",
        "\n",
        "Actualmente comprar una computadora con varios CPU's y que estos CPU's contengan varios núcleos es relativamente accesible.\n",
        "\n",
        "Es posible escribir programas en paralelo que muestres buen desempeño empleando MPI, pero si la arquitectura lo permite (memoria compartida) se logra un mejor desempeño haciendo uso OpenMP.\n",
        "\n",
        "OpenMP es un conjunto de bibliotecas, funciones y directivas de compilador (API) que permite programar en paralelo en conjunto con lenguajes como Fortran, C o C++.\n",
        "\n",
        "Es importante recordar que OpenMP se basa en la idea de dividir (fork) una tarea grande en tareas mas pequeñas, para que finalmente sean unidos (join) los resultados.\n",
        "\n",
        "A continuación se muestra el modelo de programación en paralelo mediante memoria compartida.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/openmp/mem.PNG?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "Diagrama del paradigma fork-join.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/OpenMP/thread3.png?raw=1\" width=\"600\"> \n",
        "</center>\n",
        "\n",
        "En esta imágen, la linea azul muestra el avance del cómputo con respecto al tiempo.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Imagenes/OpenMP/thread4.png?raw=1\" width=\"600\">\n",
        "</center> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJLgoXA8IVCl"
      },
      "source": [
        "# Desempeño\n",
        "\n",
        "La idea detrás de esta forma de procesamiento en paralelo, es dividir y vencer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBIFGoxeIcSL"
      },
      "source": [
        "## ¿Cómo funciona?\n",
        "\n",
        "La forma tradicional de la programación en paralelo empleando **memoria compartida** es la siguiente:\n",
        "\n",
        "• Cuando un programa comienza su ejecución un solo hilo llamado **hilo maestro** es activado.\n",
        "\n",
        "• El hilo maestro ejecuta la parte secuencial del algoritmo. En las secciones del algoritmo donde se requiera operaciones en paralelo, el hilo maestro genera (fork) **hilos adicionales** (esclavos).\n",
        "\n",
        "• El hilo maestro y los hilos adicionalmente creados, **trabajan de manera concurrente (o en paralelo)** a través de las secciones del algoritmo en paralelo.\n",
        "\n",
        "• Al termino de la o las secciones en paralelo, los hilos adicionales son **destruidos o suspendidos**.\n",
        "\n",
        "• Finalmente el control vuelve al hilo maestro y se **unen** (join) los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSlkKBEjIhCO"
      },
      "source": [
        "## Ventajas\n",
        "\n",
        "La principal diferencia entre OpenMP y MPI es que en este ultimo, todos los procesos permanecen activos, mientras que en OpenMP se comienza con un solo hilo y se termina con un solo hilo.\n",
        "\n",
        "Se puede pensar en la programación secuencial como un caso especial de la programación en paralelo usando memoria compartida (OpenMP).\n",
        "\n",
        "La programación en paralelo usando memoria compartida abarca algoritmos en los cuales se tiene un único ciclo for que se ejecuta con varios hilos, hasta aquellos algoritmos en los que la mayoria del codigo se ejecuta en paralelo.\n",
        "\n",
        "Por lo tanto este modelo de programación en paralelo soporta paralelización incremental, lo que significa que, un algoritmo secuencial puede ser transformado en uno en paralelo un bloque a la vez.\n",
        "\n",
        "En contraste, al emplear MPI es necesario replantear el diseño del algoritmo, de manera tal que desde un principio funcione en paralelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tur77JgcEN-l"
      },
      "source": [
        "# OpenMP (API)\n",
        "\n",
        "Una vez que se tiene claro el funcionaiento de OpenMP, veamos los componentes principales de este API (interfaz de programación de aplicación)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8ZwywSzI9HX"
      },
      "source": [
        "## Directivas de compilador\n",
        "\n",
        "Una directiva de compilador en *C/C++* es llamada **pragma**.\n",
        "\n",
        "La palabra pragma, es la contracción de ''información pragmática''.\n",
        "\n",
        "Pragma es una forma de comunicarle información al compilador, esta información no es esencial en el sentido del que el compilador puede ignorar dicha información y aun así compilar el código.\n",
        "\n",
        "Sin embargo la información dentro del pragma puede ayudar al compilador a optimizar el algoritmo.\n",
        "\n",
        "Al igual que otras lineas que proveen información al compilador, un pragma comienza con #."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj0UyAECJOxD"
      },
      "source": [
        "## Otras directivas de compilador\n",
        "\n",
        "Algunas de las directivas de compilador más importantes que veremos en esta sección son:\n",
        "\n",
        "1. **parallel**: que se usa antes de un bloque que sera ejecutado en paralelo por varios hilos.\n",
        "\n",
        "2. **for**: se usa antes de un ciclo for para indicar que las iteraciones de este ciclo serán ejecutadas en paralelo.\n",
        "\n",
        "3. **parallel for**: es una combinación de las 2 directivas previas.\n",
        "\n",
        "4. **sections**: indica que un conjunto de bloques sera ejecutado en paralelo.\n",
        "\n",
        "5. **parallel sections**: combinación de prallel y sections.\n",
        "\n",
        "6. **critical**: se usa para indicar que una sección sera critica, por ejemplo para indicar que una sección de código solo puede ser accesible por un hilo a la vez.\n",
        "\n",
        "7. **single**: se usa antes de un bloque que sera ejecutado por un solo hilo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z79IN3G1Jxi8"
      },
      "source": [
        "## Funciones importantes\n",
        "\n",
        "Algunas funciones importantes que veremos en esta sección son:\n",
        "\n",
        "1. **omp_get_num_procs**: devuelve el numero de CPU's que tenga el núcleo en el cual se esta ejecutando el hilo.\n",
        "\n",
        "2. **omp_get_num_threads**: devuelve el numero de hilos activos en la actual región en paralelo.\n",
        "\n",
        "3. **omp_get_thread_num**: devuelve el identificador del hilo.\n",
        "\n",
        "4. **omp_set_num_threads**: permite establecer el numero de hilos que ejecutaran el código de la sección en paralelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_FFvlQOKD1q"
      },
      "source": [
        "# Compilación y Ejecución\n",
        "\n",
        "La manera en la que se compila (revisión sintática) y se ejecuta un programa codificado mediante OpenMP, es muy similar a como se compila y se ejecuta cualquier programa escrito en *C/C++*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_0pKijIKJSQ"
      },
      "source": [
        "## Ejemplo\n",
        "\n",
        "Otra de las grandes ventajas de OpenMP es que una vez instalado el compilador y herramientas del lenguaje C (al menos en s.o. Linux) el API de OpenMP ya esta incluido con estas.\n",
        "\n",
        "De tal forma que compilar y ejecutar codigo que emplea directivas y funciones de OpenMP es tan sencillo como:\n",
        "\n",
        "*   Para compilar: *\\$gcc -o (salida.o) -fopenmp codigoc.c*\n",
        "\n",
        "El comando anterior compila (y en caso de no haber errores) y genera un archivo ejecutable (binario) que puede ser ejecutado de la siguiente manera:\n",
        " \n",
        "*   Para ejecutar:  *\\$./salida.o*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xg6mcCXKq5o"
      },
      "source": [
        "# Glosario\n",
        "\n",
        "**Hilo** (Thread): También conocido como proceso ligero, es el encargado de ejecutar tareas sencillas dentro de algún algoritmo. Varios hilos pueden conformar un proceso.\n",
        "\n",
        "**Núcleo** (core): En computación, un núcleo es una parte del microprocesador que se encarga de leer y ejecutar tareas. Actualmente se puede adquirir computadoras que cuenten con varios CPU's y que a su vez, estos contengan varios núcleos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoDz-nxRKuQ_"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "1. Michaell J. Quuin: Parallel Programming in C with OpenMP and MPI.\n",
        "2. https://hpc-wiki.info/hpc/OpenMP\n",
        "3. Dongarra Foster: Source Book of parallel computing."
      ]
    }
  ]
}
