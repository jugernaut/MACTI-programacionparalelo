{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_RedesNeuronales.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMKo6pi3HZbzODsttuhCxnq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/desarrollo/RedesNeuronales/02_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXSdMY-R3hny"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>Perceptrón</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M. en C. Miguel Angel Pérez León."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdSUVg0fNCxN"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "El perceptrón es un tipo de neurona artificial que fue inventada en 1957 por [Frank Rosenblatt](https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon).\n",
        "\n",
        "Las principales diferencias con respecto a las neuronas vistas previamente es que el perceptrón es capaz de aprender (machine learning) y además su valores de entrada y de salida son binarios. Aunque no es complicado modificar el modelo para tratar con campos no binarios."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv34b5WB2PKL"
      },
      "source": [
        "#  Anatomía del Perceptrón\n",
        "\n",
        "Todos los elementos vistos previamente se mantienen.\n",
        "\n",
        "*   **Entradas**\n",
        "*   **Pesos**\n",
        "*   **Sesgo**\n",
        "*   **Función de activación**\n",
        "\n",
        "Aunque para el caso particular del perceptrón, la función de activavción será la conocida como **paso binario** y es tan sencilla como la siguiente imagen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "401mBZpW5qmw",
        "outputId": "76719404-c13e-49e0-9022-df3d641d55c4"
      },
      "source": [
        "# se importan algunas funciones importantes\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import math\n",
        "# dominio de las graficas\n",
        "x = np.linspace(-3, 3, 20)\n",
        "\n",
        "# funciones comunes de activasion\n",
        "PasoBinario = lambda x: np.heaviside(x,0)\n",
        "\n",
        "# Definimos algunos parámetros para la gráfica\n",
        "plt.plot(x, PasoBinario(x),label=\"Paso Binario\")\n",
        "plt.legend()\n",
        "\n",
        "# Mostramos la leyenda de las gráficas\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsMAqa3YbTyo"
      },
      "source": [
        "Es decir.\n",
        "\n",
        "$$f\\left(x\\right)=\\begin{cases}\n",
        "1 \\quad si & x\\gt0\\\\\n",
        "0 \\quad & e.o.c.\n",
        "\\end{cases}$$\n",
        "\n",
        "En el contexto de las redes neuronales podemos pensar en esta función de la siguiente manera.\n",
        "\n",
        "$$f\\left(\\vec{x}\\right)=\\begin{cases}\n",
        "1 \\quad si & \\vec{w} * \\vec{x} +b\\gt0\\\\\n",
        "0 \\quad & e.o.c.\n",
        "\\end{cases}$$\n",
        "\n",
        "Donde:\n",
        "\n",
        "*   $\\vec{w}$ es el vector de pesos asociados a las entradas.\n",
        "*   $\\vec{x}$ es el vector de entradas.\n",
        "*   $b$ es el sesgo o *bias*.\n",
        "\n",
        "Estos cambios en la función de activación se deben a que, para fines prácticos es mejor pensar en las entradas de una neurona (o red neuronal) como un vector, además recordemos que las *GPU's* estan optimizadas para operaciones con vectores y con matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_9Fue_POL2I"
      },
      "source": [
        "# Ejemplo operador *AND*\n",
        "\n",
        "Igual que en el caso del cerebro humano, existen diferentes zonas del cerebro que muestran actividad con diferentes estimulos, tratemos de diseñar un perceptrón (neurona artificial) que reproduzca el comportamiento del operador logico *AND* (&&). \n",
        "\n",
        "Recordemos la tabla de verdad de este operador lógico.\n",
        "\n",
        "| $x_1$ | $x_2$ | $and$ | \n",
        "| :-:   |    :-:|  :-:  | \n",
        "| 0     | 0     | 0     |\n",
        "| 0     | 1     | 0     |\n",
        "| 1     | 0     | 0     |\n",
        "| 1     | 1     | 1     |\n",
        "\n",
        "La idea es que podamos definir un algoritmo que funcione como el operador lógico *AND*.\n",
        "\n",
        "Pensemos que este perceptrón luce de esta forma.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/RedesNeuronales/NeuronaAND.png?raw=1\" width=\"600\">\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8A4aZheBeMH"
      },
      "source": [
        "## Inteligencia Artificial (tradicional)\n",
        "\n",
        "La forma más sencilla de definir este operador es con un *if*, es decir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVCn6cCWyiDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f13111-d256-4c8f-fdad-65f947ad96a9"
      },
      "source": [
        "'''\n",
        "  versión primitiva del perceptron\n",
        "  x: vector de entradas\n",
        "  w: vector de pesos\n",
        "'''\n",
        "def perceptrAND(x, w=None, b=None):\n",
        "    if x[0]==1 and x[1]==1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# prueba de la funcion, ¡CAMBIA EL VECTOR DE ENRTADAS!\n",
        "print(perceptrAND([0,0])) \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9f3yuaYCoXf"
      },
      "source": [
        "Esta es la forma tradicional en la cual se resolvían muchos de los problemas de inteligencia artificial antes de la llegada del *machine learning*.\n",
        "\n",
        "El código de la celda anterior funciona y resuelve el problema planteado inicialmente, sin embargo **esta solución es estática**, ya no puede modificarse por si misma para \"aprender\" un nuevo comportamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oe9M4cTDbNP"
      },
      "source": [
        "## Razonamiento cognitivo\n",
        "\n",
        "Veamos otra forma de solucionar el mismo problema.\n",
        "\n",
        "Lo primero que debemos notar de la tabla de verdad es que, si **cambiamos el orden de las entradas** ($x_1, x_2$) en cada caso, el resultado no cambia.\n",
        "\n",
        "Lo segundo que hay que notar es que la suma $\\vec{w} * \\vec{x} +b$ siempre debe ser negativa, excepto cuando $x_1=1$ y $x_2=1$, tal como se muestra en la tabla de verdad.\n",
        "\n",
        "Reescribiendo nuestra tabla de verdad para considerar las entradas del perceptrón la podemos pensar de la siguiente forma.\n",
        "\n",
        "\\begin{array}{c}\n",
        "1w_1+1w_2+b>0\\\\\n",
        "0w_1+1w_2+b\\leq0\\\\\n",
        "1w_1+0w_2+b\\leq0\\\\\n",
        "0w_1+0w_2+b\\leq0 \\tag{1}\n",
        "\\end{array}\n",
        "\n",
        "Por otro lado, sabemos que:\n",
        "\n",
        "*   $x*0=0$\n",
        "*   $1x+1x=2x $\n",
        "*   $1x=x$\n",
        "\n",
        "Combinando (1) y lo que sabemos, podemos simplificar lo anterior de la siguiente forma.\n",
        "\n",
        "\\begin{array}{c}\n",
        "2w+b>0\\\\\n",
        "w+b\\leq0\\\\\n",
        "b\\leq0\\\\ \\tag{2}\n",
        "\\end{array}\n",
        "\n",
        "De (2) podemos concluir que $2w+b$ tiene que ser un valor **positivo**, $w+b$ es **negativo o cero** y $b$ es un valor **negativo o cero**.\n",
        "\n",
        "Notemos que:\n",
        "\n",
        "\n",
        "*   $b$ no puede ser cero, ya que que de ser así $2w\\gt0$ y $w\\leq0$, lo que no puede ser verdad Por lo tanto **$b$ no puede ser cero**.\n",
        "*   $w$ debe ser positivo, si $w$ fuese negativo $2w$ también sería negativo y $2w+b$ no podría ser un valor positivo y $2w+b\\gt0$ no podría ser verdad. Por lo tanto **$w$ debe ser positivo**.\n",
        "*   ya que $w$ debe ser positivo, $b$ no puede ser cero, entonces para que $w+b\\leq0$ sea verdadero debemos elegir a **$b$ como el opuesto aditivo de $w$**.\n",
        "\n",
        "¡¡¡Ya lo tenemos!!!, modificando el código de la celda anterior tenemos lo siguiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6y-Gw3IIvtL",
        "outputId": "11fe31da-cac4-4ceb-e70b-d257daf8792b"
      },
      "source": [
        "'''\n",
        "  versión mejorada del perceptron\n",
        "  x: vector de entradas\n",
        "  w: vector de pesos\n",
        "'''\n",
        "def perceptrAND2(x, w):\n",
        "    return np.heaviside(x[0]*w[0]+x[1]*w[1]+w[2], 0)\n",
        "\n",
        "# prueba de la funcion ¡CAMBIA EL VECTOR DE ENRTADAS!\n",
        "print(perceptrAND2([0,1],[1,1,-1])) \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c6Y423jLKLG"
      },
      "source": [
        "La celda superior muestra una versión mejorada del `perceptrAND` que hace uso del conocimiento previo (axiomas matemáticos y razonamiento) y de los estimulos externos (entradas $\\vec{x}$).\n",
        "\n",
        "Sin embargo tiene el mismo problema que la versión previa del `perceptrAND`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Y0ImDdOhj3"
      },
      "source": [
        "# Perceptrón\n",
        "\n",
        "La parte realmente trascendente del modelo perceptrón es el proceso de aprendizaje, esto convierte al perceptrón en un algoritmo que aprende de la experiencia y modifica su comportamiento, veamos como se lleva a cabo este proceso.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F4nh1heOnZU"
      },
      "source": [
        "## Aprendizaje\n",
        "\n",
        "Estos son los pasos descritos en lenguaje natural, que llevan al perceptrón a ajustar sus pesos $\\vec{w}$ para realizar el proceso de aprendizaje, es decir, que logre clasificar de manera acertada el conjunto de datos que recibe como entradas $\\vec{x}$.\n",
        "\n",
        "1.   Dar un valor inicial para el vector de pesos $\\vec{w}$, a veces aleatorio, o de manera más sencilla, el vector cero $\\vec{0}$.\n",
        "2.   Para cada tupla de entrada del conjunto de entrenamiento, el perceptrón realiza las siguientes acciones:\n",
        "> *   Tratará de dar una predicción para los valores de entrada.\n",
        "> *   Esta predicción se compara con la salida esperada.\n",
        "> *   Evalua la siguiente tupla.\n",
        "\n",
        "Antes de continuar hay un par de cosas que debemos definir, de manera muy similar al error que se tiene en una aproximación numérica, vamos a determinar que tan buena es la predicción del perceptrón de la siguiente forma.\n",
        "\n",
        "`salida_esperada - salida_actual`\n",
        "\n",
        "En otras palabras, necesitamos una forma de evaluar el desempeño del perceptrón y una forma de hacerlo es mediante la resta anterior. Eso lo podemos poner en términos matemáticos tal como sigue y posteriormente le llamaremos **funcion de costos** o **funcion perdida**.\n",
        "\n",
        "$$e=y-f(\\vec{x})$$\n",
        "\n",
        "Donde $e$ es el error que se tiene entre la salida esperada denotada por $y$ contra la salida del perceptrón $f(\\vec{x})$.\n",
        "\n",
        "Dado que ambos valores son binarios, $e=y-f(\\vec{x})$ solo puede producir 3 valores, que se muestran a continuación.\n",
        "\n",
        "| $y$ |     $$f(\\vec{x})$$      | $$y - f$$ | \n",
        "| :-:      |    :-:     |  :-:    | \n",
        "| 1     | 1     | 0     |\n",
        "| 0     | 0     | 0     |\n",
        "| 1     | 0     | 1     |\n",
        "| 0     | 1     |-1     |\n",
        "\n",
        "La idea es minimizar nuestro error (función de costos), así que para este fin veamos una frase celebre del creador del perceptrón **Frank Rosenblatt**.\n",
        "\n",
        "> *   *Si la neurona se activa cuando no lo deseamos, suprimela*.\n",
        "> *   *Si la neurona no se activa cuando lo deseamos, exitala*.\n",
        "> *   *Si la neurona se activa cuando lo deseamos, no la molestes*.\n",
        "\n",
        "Ya sabemos como evaluar el desempeño de nuestro perceptrón, ahora solo resta definir como siprimirlo y como exitarlo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvAgphBSRqvy"
      },
      "source": [
        "## Premio y Castigo\n",
        "\n",
        "**Castigo**: Si el perceptrón devuelve un 1 ($f(\\vec{x})=1$), cuando el resultado esperado era un 0 ($y=0$), necesitamos hacer un ajuste disminuyendo el valor de $\\vec{w}*\\vec{x}$, ya que lo que se busca es que $f(\\vec{x})=\\vec{w}*\\vec{x}\\leq 0$.\n",
        "\n",
        "**Castigo**: Si el perceptrón devuelve un 0 ($f(\\vec{x})=0$), cuando el resultado esperado era un 1 ($y=1$), necesitamos hacer un ajuste aumentando el valor de $\\vec{w}*\\vec{x}$, ya que lo que se busca es que $f(\\vec{x})=\\vec{w}*\\vec{x}\\gt 0$.\n",
        "\n",
        "**Premio**: Si el perceptrón devuelve el valor esperado ($f(\\vec{x})=y$) entonces hay que darle un premio, es decir, no hacer algo ya que la neurona está funcionando como debe ser.\n",
        "\n",
        "Dado que no podemos modificar los valores de las entradas $\\vec{x}$ ya que son los datos que usa el perceptrón para realizar sus predicciones, solo resta modificar los valores de $\\vec{w}$.\n",
        "\n",
        "Así que en pseudocódigo, lo anterior se traduce en lo siguiente.\n",
        "\n",
        "\\begin{array}{ccc}\n",
        "\\vec{w}\\leftarrow\\vec{w}+\\vec{x} & si & y-f(\\vec{x})==0\\\\\n",
        "\\vec{w}\\leftarrow\\vec{w}-\\vec{x} & si & y-f(\\vec{x})==-1\\\\\n",
        "\\vec{w}\\leftarrow\\vec{w} & si & y-f(\\vec{x})==0 \\tag{3}\n",
        "\\end{array}\n",
        "\n",
        "En pocas palabras, para incrementar el valor de $\\vec{w}$ simplemente sumamos $\\vec{x}$ y para disminuir el valor de $\\vec{w}$ simplemente restamos $\\vec{x}$.\n",
        "\n",
        "Dado que $y-f(\\vec{x})$ produce 1, -1 ó 0 podemos simplificar reescribiendo.\n",
        "\n",
        "$$\\vec{w}\\leftarrow\\vec{w}+(y-f(\\vec{x}))*\\vec{x} \\tag{4}$$\n",
        "\n",
        "¡¡¡Listo!!!, ya tenemos el mecanismo que llevará a nuestro perceptrón a aprender y adaptarse a los datos de entrada.\n",
        "\n",
        "Vamos a usar los siguientes datos de entrenamiento.\n",
        "\n",
        "| $x_1$ | $x_2$ | Salida esperada | \n",
        "| :-:   |    :-:|            :-:  | \n",
        "| 0     | 0     | 0               |\n",
        "| 0     | 1     | 0               |\n",
        "| 1     | 0     | 0               |\n",
        "| 1     | 1     | 1               |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGRmBag0dqmI"
      },
      "source": [
        "## Entrenamiento\n",
        "\n",
        "#Valores iniciales del vector $\\vec{w}$.\n",
        "\n",
        "w = [0, 0, 0] => [bias, w1, w2]\n",
        "\n",
        "#Entradas de entrenamiento\n",
        "\n",
        "x = [1, 1, 1] => [entrada_bias, x1, x2]\n",
        "\n",
        "y = 1\n",
        "\n",
        "#Salida del perceptrón\n",
        "\n",
        "f(x) = 1 if w · x > 0\n",
        "       0 otherwise\n",
        "\n",
        "w · x == (0 * 1) + (0 * 1) + (0 * 1) == 0 \n",
        "      ∴  f(x) = 0\n",
        "\n",
        "#Comparando resultados\n",
        "\n",
        "e = y - f(x) => 1\n",
        "\n",
        "#Manazo por que no fue el resultado esperado\n",
        "\n",
        "w <- w + 1 * x  => [1, 1, 1]\n",
        "\n",
        "Y este procedimiento se repite con todos los datos de entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgDwxOwHfKgY"
      },
      "source": [
        "# Código\n",
        "\n",
        "Dado que el proceso de aprendizaje es un proceso sumamente repetitivo y gracias a que tenemos un algoritmo para llevarlo a cabo, lo más sencillo es plasmar estos conceptos en código de *Python*.\n",
        "\n",
        "Además vamos a usar el paradigma orientado a objetos para darle una apariencia más familiar a las que se usan en *API's* como *TensorFlow*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rydpZ9rAPUVi"
      },
      "source": [
        "\"\"\"\n",
        "MIT License\n",
        "Copyright (c) 2018 Thomas Countz\n",
        "Codigo tomado del sitio\n",
        "https://medium.com/@thomascountz/19-line-line-by-line-python-perceptron-b6f113b161f3\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "# Definicion de la clase que hereda de la clase object\n",
        "class PerceptrAND(object):\n",
        "\n",
        "    '''\n",
        "    Constructor que recibe los siguientes parametros\n",
        "    num_entradas:     numero de entradas del vector de entradas\n",
        "    limite:           es el limite de iteraciones mientras entrenamos\n",
        "    tasa_aprendizaje: magnitud en la que se incrementan los pesos\n",
        "    '''\n",
        "    def __init__(self, num_entradas, limite=15, tasa_aprendizaje=0.01):\n",
        "        self.limite = limite\n",
        "        self.tasa_aprendizaje = tasa_aprendizaje\n",
        "        self.pesos = np.zeros(num_entradas + 1)\n",
        "          \n",
        "    '''\n",
        "    Metodo que nos devuelve la prediccion del perceptron\n",
        "    entradas: vector de entradas para realizar la prediccion\n",
        "    '''\n",
        "    def prediccion(self, entradas):\n",
        "        # suma ponderada w*x, pesos[0] = bias\n",
        "        suma = np.dot(entradas, self.pesos[1:]) + self.pesos[0]\n",
        "        # funcion de activacion equivalente a np.heaviside\n",
        "        if suma > 0:\n",
        "          activacion = 1\n",
        "        else:\n",
        "          activacion = 0            \n",
        "        return activacion\n",
        "\n",
        "    '''\n",
        "    Metodo que entrena al percetron\n",
        "    entradas_ent: vector de vectores de entradas para entrenar\n",
        "    etiquetas:    valores esperados por cada entrada del vector de entradas\n",
        "    '''\n",
        "    def entrenamiento(self, entradas_ent, etiquetas):\n",
        "        # por cada epoca en el limite de entrenamientos\n",
        "        for _ in range(self.limite):\n",
        "            # tomamos una entrada y su respectiva etiqueta\n",
        "            for entrada, etiqueta in zip(entradas_ent, etiquetas):\n",
        "                prediccion = self.prediccion(entrada)\n",
        "                # ajuste de pesos w <- w + (y-f(x)) * x \n",
        "                self.pesos[1:] += self.tasa_aprendizaje * (etiqueta - prediccion) * entrada\n",
        "                # ajuste del bias\n",
        "                self.pesos[0] += self.tasa_aprendizaje * (etiqueta - prediccion) # *1\n",
        "                # descomentar para ver que sucede\n",
        "                '''if prediccion != etiqueta:\n",
        "                    print(\"manazo por no aprender\")\n",
        "                else:\n",
        "                    print(\"bien hecho muchacho\")\n",
        "                    \n",
        "                #print(entrada)\n",
        "                #print(prediccion)\n",
        "                #print(self.pesos)'''\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taS2cMdvkq5o"
      },
      "source": [
        "## Ejecución\n",
        "\n",
        "Veamos los resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYyNXFZApHrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c61327b-e79b-4cc0-b000-c6c194bb9cf9"
      },
      "source": [
        "entradas_ent = []\n",
        "entradas_ent.append(np.array([1, 1]))\n",
        "entradas_ent.append(np.array([1, 0]))\n",
        "entradas_ent.append(np.array([0, 1]))\n",
        "entradas_ent.append(np.array([0, 0]))\n",
        "\n",
        "etiquetas = np.array([1, 0, 0, 0])\n",
        "\n",
        "perceptron = PerceptrAND(2)\n",
        "perceptron.entrenamiento(entradas_ent, etiquetas)\n",
        "\n",
        "entradas = np.array([1, 0])\n",
        "print(perceptron.prediccion(entradas))\n",
        "\n",
        "entradas = np.array([1, 1])\n",
        "print(perceptron.prediccion(entradas))\n",
        "\n",
        "entradas = np.array([0, 0])\n",
        "print(perceptron.prediccion(entradas))\n",
        "\n",
        "entradas = np.array([0, 1])\n",
        "print(perceptron.prediccion(entradas))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "manazo por no aprender\n",
            "manazo por no aprender\n",
            "manazo por no aprender\n",
            "bien hecho muchacho\n",
            "manazo por no aprender\n",
            "manazo por no aprender\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "manazo por no aprender\n",
            "manazo por no aprender\n",
            "manazo por no aprender\n",
            "bien hecho muchacho\n",
            "manazo por no aprender\n",
            "bien hecho muchacho\n",
            "manazo por no aprender\n",
            "bien hecho muchacho\n",
            "manazo por no aprender\n",
            "manazo por no aprender\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "bien hecho muchacho\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVIBoj3V2WOc"
      },
      "source": [
        "# Aprendizaje\n",
        "\n",
        "Como podemos notar, el perceptrón ha aprendido y despues de haberlo entrenado ya logra reproducir el comportamiento del operador lógico *AND* (&&) y eso que solo hemos hecho uso de un solo perceptrón.\n",
        "\n",
        "Ya que comprendimos su funcionamiento, surgen nuevas preguntas:\n",
        "\n",
        "*   ¿Podémos hacer que este perceptrón logre \"aprender\" **cualquier comportamiento**?.\n",
        "*   ¿Qué sucede si generamos \"capas\" de **perceptrones enlazados** donde las salidas de toda una capa sean las entradas de otra nueva capa?.\n",
        "*   ¿Podemos pensar en el proceso de aprendizaje como un **problema de minimización** de costos?, y de ser así ¿conoces algúna función matemática que nos ayude a encontrar **valores mínimos**?.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oniRCJqcpkPf"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/desarrollo/Figuras/redesNeuronales/perceptron1.gif?raw=1\" width=\"550\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AQHpP046Z6_"
      },
      "source": [
        "#  Referencias\n",
        "\n",
        "*   [Prometeo](https://github.com/jugernaut/Prometeo)\n",
        "*   [Perceptron](https://medium.com/@thomascountz/19-line-line-by-line-python-perceptron-b6f113b161f3)\n",
        "*   [Brilliant](https://brilliant.org/practice/intelligent-computers-menace/?chapter=introduction-to-neural-networks)\n",
        "*   [Simulador](https://ml4a.github.io/ml4a/es/neural_networks/)\n",
        "*   [NetLogo](https://ccl.northwestern.edu/netlogo/)\n",
        "*   [Red neuronal desde cero](https://futurelab.mx/redes%20neuronales/inteligencia%20artificial/2019/06/25/intro-a-redes-neuronales-pt-1/)\n",
        "*   [Libro Web](http://neuralnetworksanddeeplearning.com/index.html)\n",
        "*   [Aprendizaje profundo](https://www.deeplearningbook.org/)\n",
        "*   [Lista de videos](https://www.youtube.com/playlist?list=PLo8YL3HL50lUHQS80oE_ypxFi0Y3uCVal)\n",
        "*   [Algebra Lineal](https://www.youtube.com/playlist?list=PLIb_io8a5NB2DddFf-PwvZDCOUNT1GZoA)\n"
      ]
    }
  ]
}