{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computo_en_paralelo_SCP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Introduccion/Computo_en_paralelo_SCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw2tNz_RtpGP"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\r\n",
        "  <h1 align=\"center\"><i>Cómputo en Paralelo</i></h1>\r\n",
        "  </font>\r\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\r\n",
        "  <h5 align=\"center\"><i>Profesor: M.en.C. Miguel Angel Pérez León.</i></h5>\r\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón.</i></h5>\r\n",
        "    <h5 align=\"center\"><i>Ayudante: Mario Arturo .</i></h5>\r\n",
        "  <h5 align=\"center\"><i>Materia: Seminario de programación en paralelo..</i></h5>\r\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Yf4M8Gu5Nl"
      },
      "source": [
        "#Introducción.\r\n",
        "\r\n",
        "El hardware se mejora constantemente y el día de mañana sera mas rápido que el día de hoy, así que como consecuencia de la **ley de Moore**, podríamos esperar a comprar una computadora mas \"rápida\" y eficiente que la que tenemos actualmente. Sin embargo mediante programación en paralelo, se pueden optimizar y agilizar los algoritmos empleados actualmente.\r\n",
        "\r\n",
        "$\\color{blue}{Definición}$. Ley de Moore:\r\n",
        "\r\n",
        "El numero de transistores por unidad de superficie en circuitos integrados, se duplicara cada año. En consecuencia, la velocidad de computo relacionada directamente al hardware se vera duplicada cada año\r\n",
        "\r\n",
        "<center>\r\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/ComputoParalelo/moore.png?raw=1\" width=\"600\"> \r\n",
        "</center>\r\n",
        "\r\n",
        "<center>\r\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/ComputoParalelo/more2.jpg?raw=1\" width=\"600\"> \r\n",
        "</center>\r\n",
        "\r\n",
        "La computación en paralelo es ahora considerada una forma estándar para científicos e ingenieros para resolver problemas tan diversos como, evolución galáctica, modelado climático, diseño aeronáutico y dinámica molecular, por mencionar algunas.\r\n",
        "\r\n",
        "De tal manera que es conveniente tener en claro que significa el cómputo en paralelo y para eso es necesario tener claras las siguientes definiciones.\r\n",
        "\r\n",
        "\r\n",
        "$\\color{blue}{Definición}$.Cómputo en paralelo:\r\n",
        "\r\n",
        " Es el uso de \"elementos de procesamiento\" en paralelo para reducir el tiempo empleado en resolver un problema computable.\r\n",
        "\r\n",
        "\r\n",
        "$\\color{blue}{Definición}$.Cómputo en paralelo:\r\n",
        "\r\n",
        "Sistema de cómputo multi-procesador, que puede soportar computo en paralelo. Existen 2 categorías importantes de computadoras en paralelo, multicomputadoras (comúnmente conocidas como Cluster) y multi-procesadores centralizados.\r\n",
        "\r\n",
        "\r\n",
        "$\\color{blue}{Definición}$.Cluster:\r\n",
        "\r\n",
        "Sistema de cómputo construido con base en múltiples computadoras que se conectan a través de una red. Los procesadores en cada computadora interactúan entre si enviando y recibiendo mensajes mediante la red.\r\n",
        "\r\n",
        "$\\color{blue}{Definición}$. Multi-procesadores Centralizados:\r\n",
        "\r\n",
        "También llamados multi-procesadores simétricos (MPS), es un sistema mas integral en el cual todos los CPU's comparten acceso a un sistema global de memoria.\r\n",
        "\r\n",
        "\r\n",
        "$\\color{blue}{Definición}$. Multi-procesadores Desentralizados GPU's:\r\n",
        "\r\n",
        "Sistema de computo multi-procesador, en el que el computo se realiza haciendo uso de una o mas tarjetas graficas (GPU). A diferencia de las definiciones anteriores, al emplear GPU's no se tiene un sistema global de memoria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLAv6jYtzhC0"
      },
      "source": [
        "#Como representarlo.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYMlTe__0mcx"
      },
      "source": [
        "##Arquitecturas.\r\n",
        "\r\n",
        "Existen múltiples arquitecturas de computadoras, pero las mas comunes son las siguientes\r\n",
        "\r\n",
        "<center>\r\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/ComputoParalelo/SMP.png?raw=1\" width=\"600\"> \r\n",
        "</center>\r\n",
        "\r\n",
        "<center>\r\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/master/Imagenes/ComputoParalelo/cluster.png?raw=1\" width=\"600\"> \r\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcg74kkG0olo"
      },
      "source": [
        "##Distintas formas de identificarlo.\r\n",
        "\r\n",
        "Existen muchas formas para poder identificar si existe la posibilidad de emplear alguna técnica de paralelización.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "1.   Grafica de dependencia de datos: es un tipo de grafica dirigida en la cual cada vértice representa una tarea que debe ser realizada. Una arista del vértice u al vértice v, significa que la tarea u, debe ser realizada antes de que la tarea v comience. Se dice que ''la tarea v no es dependiente de la tarea u'' si no existe un camino de u a v por lo tanto ambas tareas son independientes y pueden ser realizadas de manera concurrente.\r\n",
        "2.   Paralelizmo con datos: una grafica de dependencia de datos muestra cuando existen tareas dependientes, unas de las otras.\r\n",
        "3.   Paralelizmo funcional: una grafica de dependencia de datos muestra paralelismo funcional cuando hay diferentes tareas aplicando diferentes operaciones a datos diferentes.\r\n",
        "4.   Pipeline: incluso cuando se tiene algún tipo de dependencia, existe la técnica del pipeline que permite generar una 'linea de ensamblaje' con la cual se pueden ejecutar multiplies procesos.\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exPfMdTT1qTb"
      },
      "source": [
        "#Estándares de programación.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJzQim502Fp9"
      },
      "source": [
        "##OpenMP y MPI.\r\n",
        "\r\n",
        "Debido a que existen múltiples arquitecturas y un sin fin de formas de implementar un algoritmo (incluso en paralelo), surgió la necesidad de crear estándares de tal manera que fuera mas sencillo poder crear algoritmos en paralelo que funcionaran en múltiples arquitecturas y que pudieran ser escalables.\r\n",
        "\r\n",
        " \r\n",
        "En este caso el termino escalable hace referencia a que una vez que se cuente con un hardware mas potente, el algoritmo definido mediante alguno de estos estándares (MPI u OpenMP), podrá ser compilado y ejecutado sin necesidad de realizar cambio alguno, y simplemente por hacer uso de hardware más potente dicho algoritmo tendrá un mejor desempeño.\r\n",
        "\r\n",
        "La principal diferencia entre OpenMP y MPI es que OpenMP se basa en el concepto de memoria compartida, mientras que MPI no contempla este requisito, sin embargo se pueden generar algoritmos híbridos, que obtengan lo mejor de ambos enfoques.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBQlLClc2U1N"
      },
      "source": [
        "###MPI.\r\n",
        "\r\n",
        "MPI (Message Passing Interface) es un estándar para bibliotecas (API) que emplean el paso de mensajes como método de comunicación entre procesos. Bibliotecas de este tipo son accesible en casi cualquier sistema de computo en paralelo.\r\n",
        "\r\n",
        "\r\n",
        "Versiones gratuitas de MPI también están disponibles para desarrollo de algoritmos empleando clusters.\r\n",
        "\r\n",
        "\r\n",
        "Cada vez mas las computadoras en paralelo son construidas con base en multiprocesadores simétricos (MPS). Dentro de cada MPS el CPU tiene un espacio de memoria compartida, por lo que MPI es una forma completamente recomendable para que procesos en diferentes MPS se comuniquen entre si."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pNE1W0D2kV-"
      },
      "source": [
        "###OPENMP\r\n",
        "\r\n",
        "OpenMP al igual que MPI es un API para la programación multiproceso de memoria compartida, con la peculiaridad que puede ser empleada en múltiples plataformas debido a que es un estándar.\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Esta basado en el modelo fork-join (divide y vencerás), el cual propone dividir (fork) una tarea muy pesada en muchos hilos de menor complejidad, posteriormente se recolectan los resultados y finalmente se unen en un único resultado (join).\r\n",
        "\r\n",
        " \r\n",
        "\r\n",
        "Al emplear alguna directiva de compilador OpenMP, se debe especificar en que momento sincronizar los resultados del bloque en cuestión. Es decir que todo ese bloque se marca en paralelo y se ejecutaran múltiples hilos según la característica de dicha directiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ww_YhgIG2r4s"
      },
      "source": [
        "#Referencias.\r\n",
        "\r\n",
        "1. Michaell J. Quuin:Parallel Programming in C with OpenMP and MPI.\r\n",
        "\r\n",
        "2. Referencias Libro Web: Introduccion a Python.\r\n",
        "\r\n",
        "3. Referencias Dongarra Foster: Source Book of parallel computing."
      ]
    }
  ]
}
