{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/ProgramacionEnParalelo/blob/desarrollo/Envoltorios/04_TensorFlow2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKcKm7OJbfaC"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>TensorFlow</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M. en C. Miguel Angel Pérez León</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Mario Arturo</i></h5>\n",
        "  <h5 align=\"center\"><i>Materia: Seminario de programación en paralelo</i></h5>\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL3l51BpO_hL"
      },
      "source": [
        "## Introducción\n",
        "\n",
        "*TensorFlow* es una *API* desarrollado por *Google* y es el conjunto de herramientas libres que se utiliza más ampliamente en el desarrollo de inteligencia artificial.\n",
        "\n",
        "Existen multiples versiones de *TensorFlow*, sin embargo en escencia vamos a contar con la version 1.x y la versión 2.x. La principal diferencia entre ambas es que la versión 1.x hace uso de **grafos** para representar el flujo de los datos y la versión 2.x se apoya en [Keras](https://enmilocalfunciona.io/deep-learning-basico-con-keras-parte-1/) para generar modelos más intuitivos.\n",
        "\n",
        "En este documento nos enfocaremos en la versión 2.x de *TensorFlow* con soporte para *GPU's*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUR6fBxlqMgC"
      },
      "source": [
        "## Mapa auto organizado (*SOM*)\n",
        "\n",
        "Un mapa auto organizado o *SOM* por sus siglas en inglés (*self-organized map*) es una de las redes neuronales más sencilla y fáciles de implementar pero no por eso es un algoritmo que no tenga aplicación actualmente.\n",
        "\n",
        "Este tipo de red neuronal fue creado en la decada de los 80's por el por el finlandés Teuvo Kohonen y se basa en modelos matemáticos de Alan Turing.\n",
        "\n",
        "La idea detrás de este algoritmo es muy sencilla y se describe de manera breve a continuación:\n",
        "\n",
        "*   Comenzamos con una red o mapa (matriz) de vectores o incluso de matrices en la cual todas las neuronas o entradas del mapa contienen valores aleatorios.\n",
        "*   Por cada elemento en la lista de entrenamiento, se evalua la norma (distancia) de este elemento contra cada neurona en la red.\n",
        "*   Tomamos aquella neurona cuya norma haya sido la menor y modificamos los valores de las neuronas vecinas para que se parezcan un poco al vector evaluado en esa iteración.\n",
        "*   Se repite este proceso hasta terminar las iteraciones ó en caso de que la norma de la red actual y la red anterior no difiere mucho.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQdgCiNDrBRg"
      },
      "source": [
        "### Formalización del algoritmo\n",
        "\n",
        "Para dar un formalización de este algoritmo es necesario definir un conjunto de variables que son usadas durante el proceso de entrenamiento y clasificación de la red nueronal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGzJ_yoeEYGI"
      },
      "source": [
        "#### Variables\n",
        "\n",
        "*   $s$ es la iteración actual.\n",
        "*   $\\lambda$ cantidad de ciclos de entrenamiento o epocas.\n",
        "*   $t$ es el índice del vector de entrada en el conjunto de datos de entrada $D$.\n",
        "*   $D(t)$ es un vector de entrada de índice $t$ del conjunto de datos de entrada $D$.\n",
        "*   $v$ es el índice de una neurona en el mapa.\n",
        "*   $W_v$ es el vector de pesos de la neurona v.\n",
        "*   $u$ es el índice de la neurona cuya norma es la menor con respecto de $W_v$\n",
        "*   $\\Theta (u,v,s)$ es la función de vecindad que determina cuáles neuronas serán modificadas.\n",
        "*   $\\alpha (s)$ es una función que restringe el aprendizaje conforme avanzan las iteraciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNvm0iYHEaVH"
      },
      "source": [
        "#### Algoritmo\n",
        "\n",
        "1.   Hacer un mapa (red) de neuronas con vectores de pesos aleatorios.\n",
        "2.   Tomar un vector de entrada $D(t)$.\n",
        "\n",
        ">1.   Iterar por cada neurona del mapa.\n",
        "\n",
        ">>1.   Calcular la distancia entre el vector de entrada y los vectores de pesos de las neuronas del mapa.\n",
        "2.   Mantener la neurona que ha tenido la menor distancia (norma), esta neurona será el best matching unit (BMU).\n",
        "\n",
        ">2.   Actualizar las neuronas en la vecindad del BMU.\n",
        "\n",
        ">> 1.   $W_{v}\\left(s+1\\right)=W_{v}\\left(s\\right)+\\Theta\\left(u,v,s\\right)\\alpha\\left(s\\right)\\left(D\\left(t\\right)-W_{v}\\left(s\\right)\\right)$\n",
        "\n",
        "3.   Incrementar $s$ y volver al paso 2, mientras $s<\\lambda$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t_BRrcZMhm1"
      },
      "source": [
        "## *Tensor Flow*\n",
        "\n",
        "Existen varias formas de hacer uso de *TensoFlow*, sin embargo dadas las características del curso, nos vamos a enfocar en la forma declarativa.\n",
        "\n",
        "Lo primero que necesitamos hacer para acceder a la versión de *TensorFlow* con soporte para GPU's en Google Colab, es desinstalar la versión actual e instalar la versión con soporte para GPU's, además de cambiar el entorno de ejecución del jupyter.\n",
        "\n",
        "1.   Para cambiar el entorno de ejecución: Primero, ir al menú *Runtime o Entorno de ejecución*, seleccionar *Cambiar tipo de tiempo de ejecución*, y en el cuadro emergente, en *Acelerador de hardware*, seleccione *GPU*, guardamos el cambio y listo.\n",
        "2.   Posteriormente validamos que se tenga acceso al *GPU*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suqiw16TkJh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b64c4c-e63a-44fe-e6f8-fa19ad972c16"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.test.is_gpu_available())\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-3a0be62431d3>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "True\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f6uXZ-6kpx8"
      },
      "source": [
        "La celda superior nos indica que tenemos acceso al GPU's y que harémos uso de la versión 2.5.0 de *TensoFlow*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZABpYxgBKIpq"
      },
      "source": [
        "### *FrameWork*\n",
        "\n",
        "Inicialmente TensorFlow fue diseñado para hacer uso de grafos para representar los datos y las operaciones que se realizan sobre los mismos. Parte de esa forma de trabajar aun funciona con la versión 2.x de *TensorFlow* y es buena idea comenzar con la misma.\n",
        "\n",
        "Como en la mayoria de *FrameWorks*, *TensorFlow* cuenta con multiples elementos que ayudan al programador, algunos de estos elementos son:\n",
        "\n",
        "\n",
        "*   Constantes.\n",
        "*   Variables.\n",
        "*   Tensores.\n",
        "*   Escalares.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYXbD2XBKhTb"
      },
      "source": [
        "#### Operaciones\n",
        "\n",
        "Pensemos que, como parte de nuestro modelo necesitamos procesar 2 entradas y devolver un resultado. Esta operación es muy sencilla pero muestra como se debe pensar en el flujo de los datos.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0XkJHIfnB2g",
        "outputId": "e887bbf6-72d4-4db8-b304-c67f95d94810"
      },
      "source": [
        "# se realiza la suma de 3 y 5 haciendo uso de tf y del metodo add\n",
        "a = tf.add(3, 5)\n",
        "# mostramos el elemento del grafo llamado a\n",
        "print(a)\n",
        "# se muestra el resultado de la operación en el nodo a\n",
        "print(a.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1QYAfrbo7Cy"
      },
      "source": [
        "Podemos pensar en esta operación de la siguiente forma.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/sumaTF.png?raw=true\" width=\"700\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHbfmowIXru0"
      },
      "source": [
        "#### Ventaja del grafo\n",
        "\n",
        "El grafo nos da la ventaja de construir de manera organizada y visual la forma en la que se procesan los datos.\n",
        "\n",
        "Ahora pensemos que deseamos realizar la siguiente operación. \n",
        "\n",
        "$$\\left(2\\times3\\right)^{\\left(2+5\\right)}$$\n",
        "\n",
        "¿Cómo se vería este grafo y cómo se escribe esta operación con *TensorFlow*?.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/powTF.png?raw=true\" width=\"700\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "im0VZhAlrO_F",
        "outputId": "c505590b-76fd-480a-916e-e31752363878"
      },
      "source": [
        "# Variables de Python\n",
        "x = 2\n",
        "y = 3\n",
        "\n",
        "# Operaciones y grafo de TensorFlow\n",
        "op1 = tf.add(x, y)         \n",
        "op2 = tf.multiply(x, y)    \n",
        "op3 = tf.pow(op2, op1)\n",
        "\n",
        "# Veamos el nodo op3\n",
        "print(op3)\n",
        "\n",
        "# El resultado de dicha operación es\n",
        "print(op3.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(7776, shape=(), dtype=int32)\n",
            "7776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_Ym3FtKRP1t"
      },
      "source": [
        "#### Red Neuronal\n",
        "\n",
        "Conforme vamos agregando más nodos al grafo, este cada vez se parece más a una red, incluso podemos llegar a un punto en el cual el grafo sea similar a una red neuronal.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/ProgramacionEnParalelo/blob/main/Imagenes/Envoltorios/som.gif?raw=true\" width=\"700\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nKaftH_QgXy"
      },
      "source": [
        "### Acceso a la *GPU*\n",
        "\n",
        "En la sección anterior vimos que ya se contaba con acceso a la GPU, ahora vamos a ver que tan buena idea es hacer uso de la misma.\n",
        "\n",
        "Vamos a definir 2 mpetodos que hagan uso de TensorFlow, uno de ellos procesando los datos en la *CPU* y el otro en la *CPU*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCR8gKF2Q70u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2876bd7-6809-4722-c1b4-8e5cdf5a863e"
      },
      "source": [
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print(\n",
        "        '\\n\\nNo se tiene habilitado el acceso a la GPU, revisa la configuracion '\n",
        "        'del notebook.\\n\\n')\n",
        "    raise SystemError('No se cuenta con GPU')\n",
        "\n",
        "def cpu():\n",
        "    # con esta linea se procesa el bloque en la CPU\n",
        "    with tf.device('/cpu:0'):\n",
        "\n",
        "      random_image_cpu = tf.random.normal((2, 2, 2, 3))\n",
        "      #net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "      print(random_image_cpu.numpy())\n",
        "      #return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      random_image_gpu = tf.random.normal((10, 10, 10, 3))\n",
        "      net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "      return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# Provemos ambos metodos\n",
        "cpu()\n",
        "#gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "#gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "#print(gpu_time)\n",
        "#print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-0.48568574  0.41525906 -0.36013386]\n",
            "   [ 0.6819348   0.5882328   0.55500996]]\n",
            "\n",
            "  [[ 0.84039044 -0.19969532 -1.8247157 ]\n",
            "   [-1.3081027  -1.3476518  -1.1336387 ]]]\n",
            "\n",
            "\n",
            " [[[-0.48133856  0.4714011   1.9848697 ]\n",
            "   [-1.9595354   0.02352175 -2.17152   ]]\n",
            "\n",
            "  [[-1.095417    0.4774125   0.99265563]\n",
            "   [ 0.32587206 -0.17044206  0.6095455 ]]]]\n",
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "[[[[-1.3594106  -0.9543706  -0.5387276 ]\n",
            "   [ 0.69745916 -2.0503354   0.05877934]]\n",
            "\n",
            "  [[-0.1608548  -0.545087    0.44213304]\n",
            "   [ 0.13503575  1.0892397  -0.12103062]]]\n",
            "\n",
            "\n",
            " [[[ 1.1347486  -0.27521664  0.66298926]\n",
            "   [-0.5906811  -0.21181846 -0.02122292]]\n",
            "\n",
            "  [[-0.9328345   2.1410418   0.03196247]\n",
            "   [ 0.3500834   0.53867894 -0.33968747]]]]\n",
            "[[[[-0.76909536  0.23411484 -1.051287  ]\n",
            "   [-0.787789    0.7818374   0.84038025]]\n",
            "\n",
            "  [[-1.0035373   0.76670384 -0.2297457 ]\n",
            "   [ 0.02699127 -0.19302596  0.7482072 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.8632968  -1.0977119   0.6170479 ]\n",
            "   [-0.58415145 -1.9790988   1.339309  ]]\n",
            "\n",
            "  [[-0.98995775  0.8305699   0.26021564]\n",
            "   [ 1.1242857  -1.3045541   1.1466938 ]]]]\n",
            "[[[[ 0.2454339  -0.6824814   0.23944682]\n",
            "   [-1.621088   -1.1715604   1.100205  ]]\n",
            "\n",
            "  [[ 1.4647396  -0.967997   -0.45136958]\n",
            "   [ 0.5141597   1.0793632   0.9847914 ]]]\n",
            "\n",
            "\n",
            " [[[-0.9257258   0.78245354 -0.04535221]\n",
            "   [ 0.8807674  -0.45420554 -1.2542614 ]]\n",
            "\n",
            "  [[-0.36777365  1.0863436   1.0327327 ]\n",
            "   [ 0.42815447 -0.11121745  0.2894952 ]]]]\n",
            "[[[[ 1.4646941  -1.0022026  -0.75938404]\n",
            "   [-0.6311304  -1.3414798   0.31890118]]\n",
            "\n",
            "  [[-0.65812695 -0.5511129   0.5594759 ]\n",
            "   [ 0.0494058  -0.5024404  -1.3175093 ]]]\n",
            "\n",
            "\n",
            " [[[-1.4101514   0.88708466  0.11566123]\n",
            "   [-1.9282275  -0.35278347 -1.5453213 ]]\n",
            "\n",
            "  [[ 1.1772588  -2.0823333   1.8106692 ]\n",
            "   [ 1.4300668  -0.96662927 -0.24049184]]]]\n",
            "[[[[-1.0100062   0.5911288  -0.47687766]\n",
            "   [-0.6882124  -0.14541551  0.49432892]]\n",
            "\n",
            "  [[ 0.7078548   1.0621812  -1.1798007 ]\n",
            "   [-0.29649132 -1.0221153  -0.51234466]]]\n",
            "\n",
            "\n",
            " [[[-0.9708344   0.94665605  0.8312471 ]\n",
            "   [-1.8138436   1.2150396  -0.04461408]]\n",
            "\n",
            "  [[-1.0786538  -0.11354827 -1.247519  ]\n",
            "   [ 1.1504372  -1.120701    0.18269144]]]]\n",
            "[[[[ 1.500024    0.98848486 -1.2484827 ]\n",
            "   [ 2.1398265   1.1065354   0.847883  ]]\n",
            "\n",
            "  [[ 0.3328796  -0.7420114  -0.38659215]\n",
            "   [ 1.2423385  -0.79713905  1.7856017 ]]]\n",
            "\n",
            "\n",
            " [[[ 0.7801232  -0.41915828  0.06501961]\n",
            "   [-0.04170065 -0.82961833 -0.6521209 ]]\n",
            "\n",
            "  [[ 0.09638228 -0.46907145 -0.61572164]\n",
            "   [ 0.03757083 -0.26936594 -1.0996032 ]]]]\n",
            "[[[[ 1.3800982  -0.4583032  -0.09555059]\n",
            "   [-0.34431002 -0.34232095 -0.10863519]]\n",
            "\n",
            "  [[-0.40961647 -0.6014987   1.3335683 ]\n",
            "   [-0.02464872  1.8477148  -0.78958803]]]\n",
            "\n",
            "\n",
            " [[[ 1.411197    0.79906875  1.5437441 ]\n",
            "   [-3.1973991  -0.8086354   1.8629307 ]]\n",
            "\n",
            "  [[ 0.21103126 -1.2942618  -1.805859  ]\n",
            "   [ 1.4417855  -0.41910318 -1.2150147 ]]]]\n",
            "[[[[-0.9768408   1.6260605   1.1584083 ]\n",
            "   [-0.47998497  0.88437957  0.87588197]]\n",
            "\n",
            "  [[-0.38938513  1.5166035   1.1453044 ]\n",
            "   [-1.5424986  -0.5024088  -0.4129377 ]]]\n",
            "\n",
            "\n",
            " [[[-0.33544523 -0.6492128  -2.6076987 ]\n",
            "   [ 0.9290498  -1.4749695  -1.5917702 ]]\n",
            "\n",
            "  [[-0.21829474 -1.2930169   0.70952356]\n",
            "   [-0.65187156  0.9074291  -1.1856972 ]]]]\n",
            "[[[[-0.90098405  0.25039196 -0.25267607]\n",
            "   [-1.1603416  -1.3403649  -0.00225166]]\n",
            "\n",
            "  [[ 0.8989702  -2.1644108  -0.17323424]\n",
            "   [-1.3051591  -0.15607877  0.31236413]]]\n",
            "\n",
            "\n",
            " [[[ 1.2297205   1.9307783  -0.42363745]\n",
            "   [-0.44701472 -0.56276107  1.9816997 ]]\n",
            "\n",
            "  [[ 0.04731781  1.3822654   0.35969853]\n",
            "   [-1.0756631   0.36942363  0.4185634 ]]]]\n",
            "[[[[-0.18879408  0.8380387   0.9134498 ]\n",
            "   [ 0.65500015  1.2935481  -1.5553586 ]]\n",
            "\n",
            "  [[ 0.9259776   0.43089467 -0.14600977]\n",
            "   [-1.859444    1.3005161  -0.93177927]]]\n",
            "\n",
            "\n",
            " [[[-0.81252927  0.6759815   0.32725427]\n",
            "   [-1.432436    0.57508725  1.7349524 ]]\n",
            "\n",
            "  [[ 1.711774   -0.19544378  0.07461634]\n",
            "   [ 0.9169268   1.1245025  -0.3234534 ]]]]\n",
            "0.014992495000001327\n",
            "GPU (s):\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd-B7cS3caHl"
      },
      "source": [
        "## Extendiendo este modelo\n",
        "\n",
        "La implementación en este documento se realizo con colores, ya que facilitan la comprensión del funcionamiento del algoritmo en general.\n",
        "\n",
        "Sin ambargo esta red neuronal puede ser aplicada a cualquier espacio vectorial, en otras palabras, este algoritmo puede ser aplicado a cualquier objeto que podamos representar en forma de vector o matriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOr5r_Zfdzg4"
      },
      "source": [
        "### Clasificación de Documentos o Imágenes\n",
        "\n",
        "Para clasificar documentos el algoritmo es exactamente el mismo, lo único que cambia es que tenemos que obtener un **vector caracteristico** para los documentos que nos interes clasificar. Este vector caracteristico se puede obtener de formas muy variadas y una de ellas es **contando la frecuencia de las plabras** que aparecen en dicho documento.\n",
        "\n",
        "Respecto a la clasificación de imágenes, una imagen finalmente es un **mapa de pixeles**, mismo que puede ser representado por un vector de vectores, es decir un **vector de colores**, lo que en si ya un vector caracteristico de dicha imágen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAh_UjLcaKr7"
      },
      "source": [
        "## Referencias\n",
        "\n",
        "*   https://codesachin.wordpress.com/2015/11/28/self-organizing-maps-with-googles-tensorflow/\n",
        "*   http://www.saedsayad.com/clustering_som.htm\n",
        "*   https://www.tensorflow.org/install\n",
        "*   https://relopezbriega.github.io/blog/2016/06/05/tensorflow-y-redes-neuronales/\n",
        "\n"
      ]
    }
  ]
}